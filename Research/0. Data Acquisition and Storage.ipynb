{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import tqdm\n",
    "import os\n",
    "import boto3\n",
    "from Py_Files import credentials\n",
    "from Py_Files import factset_api\n",
    "from Py_Files import factset_fields\n",
    "\n",
    "data_dir = '/Users/joeybortfeld/Documents/QML Solutions Data/'\n",
    "s3_dir = 's3://qml-research-data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load the Factset Universe (All Fsym IDS) into Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/ftykl3xj33b10g8wq6w9ccmh0000gn/T/ipykernel_23835/3681710329.py:1: DtypeWarning: Columns (17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  factset_universe = pd.read_csv('/Users/joeybortfeld/Downloads/qml_universe_ids.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start load_universe_dict()\n",
      "-- universe counts:\n",
      "--  full : 98204\n",
      "--  $10B : 4692\n",
      "--  $5B : 7706\n",
      "--  $1B : 21165\n",
      "--  $500M : 30545\n",
      "--  $250M : 41927\n",
      "--  $100M : 57750\n"
     ]
    }
   ],
   "source": [
    "factset_universe = pd.read_csv('/Users/joeybortfeld/Downloads/qml_universe_ids.csv')\n",
    "\n",
    "universe_dict = factset_api.load_universe_dict(factset_universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download Assets in USD using the Factset Fundamentals API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = factset_api.batch_fundamental_download(fsym_list=universe_dict['$1B'],\n",
    "                               field_list=['FF_ASSETS'],\n",
    "                               currency='USD',\n",
    "                               periodicity_list=['annual', 'quarterly' 'semi_annual'],\n",
    "                               start_date='1990-01-01',\n",
    "                               end_date='2024-12-31',\n",
    "                               skip_if_done=True,\n",
    "                               output_folder='/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_assets_in_usd/',\n",
    "                               factset_api_authorization=credentials.factset_api_authorization)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download All Metrics in Local Currency using the Factset Fundamentals API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = factset_api.batch_fundamental_download(fsym_list=universe_dict['full'],\n",
    "                               field_list=factset_fields.fundamental_fields,\n",
    "                               currency='LOCAL',\n",
    "                               periodicity_list=['annual', 'quarterly' 'semi_annual'],\n",
    "                               start_date='1990-01-01',\n",
    "                               end_date='2024-12-31',\n",
    "                               skip_if_done=True,\n",
    "                               output_folder='/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/',\n",
    "                               factset_api_authorization=credentials.factset_api_authorization)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Review Downloaded Data on Local Storage and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/annual/ 21165\n",
      "/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/quarterly/ 21165\n",
      "/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/semi_annual/ 8281\n",
      "/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_assets_in_usd/annual/ 98205\n",
      "/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_assets_in_usd/semi_annual/ 98204\n"
     ]
    }
   ],
   "source": [
    "# list the file counts stored locally\n",
    "\n",
    "folder_list = [\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/annual/',\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/quarterly/',\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/semi_annual/',\n",
    "\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_assets_in_usd/annual/',\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_assets_in_usd/semi_annual/',\n",
    "]\n",
    "\n",
    "for this_folder in folder_list:\n",
    "    file_list = os.listdir(this_folder)\n",
    "    \n",
    "    print(this_folder, len(file_list))\n",
    "\n",
    "        # for this_file in file_list:\n",
    "    #     aws_s3.copy_file_to_s3(local_file_path=this_folder + this_file, \n",
    "    #                             s3_bucket='qml-solutions-new-york', \n",
    "    #                             s3_key='factset-api-fundamentals/', \n",
    "    #                             aws_access_key_id=credentials.aws_access_key_id, \n",
    "    #                             aws_secret_access_key=credentials.aws_secret_access_key,\n",
    "    #                             verbose=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer local files to s3\n",
    "\n",
    "\n",
    "folder_list = [\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/annual/',\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/quarterly/',\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_fundamentals/semi_annual/',\n",
    "\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_assets_in_usd/annual/',\n",
    "    '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_assets_in_usd/semi_annual/',\n",
    "]\n",
    "\n",
    "for this_folder in folder_list:\n",
    "    file_list = os.listdir(this_folder)\n",
    "    \n",
    "    print(this_folder, len(file_list))\n",
    "\n",
    "    for this_file in tqdm.tqdm(file_list):\n",
    "        aws_s3.copy_file_to_s3(local_file_path=this_folder + this_file, \n",
    "                                s3_bucket='qml-solutions-new-york', \n",
    "                                s3_key='XXXXXXXXXXXXXXX',\n",
    "                                aws_access_key_id=credentials.aws_access_key_id, \n",
    "                                aws_secret_access_key=credentials.aws_secret_access_key,\n",
    "                                verbose=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Get the Factset Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_max_assets_in_usd = False\n",
    "\n",
    "if build_max_assets_in_usd:\n",
    "\n",
    "    # ASSEMBLE ASSETS IN USD ACROSS THE ENTIRE FSYM_ID UNIVERSE\n",
    "    output_folder = '/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_annual_assets_in_usd/'\n",
    "    fsym_id_list = output_files = os.listdir(output_folder)\n",
    "    fsym_id_list = [f.replace('.csv', '') for f in fsym_id_list]\n",
    "    print('file count:', len(fsym_id_list))\n",
    "\n",
    "\n",
    "    counter = 0\n",
    "    results = []\n",
    "    for fsym_id in tqdm.tqdm(fsym_id_list):\n",
    "\n",
    "        if counter == 100:\n",
    "            pass\n",
    "        counter +=1 \n",
    "\n",
    "        if fsym_id[0] == '.':\n",
    "            print('error:', fsym_id)\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(output_folder + f'{fsym_id}.csv')\n",
    "        results.append([fsym_id, df['value'].max()])\n",
    "\n",
    "    max_assets_in_usd_df = pd.DataFrame(results, columns=['fsym_id', 'max_assets_in_usd'])\n",
    "    max_assets_in_usd_df.to_csv('/Users/joeybortfeld/Downloads/max_assets_in_usd_by_fsym_id.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total primary issue universe size: 98205\n",
      "--count with max assets > $10B: 4692\n",
      "--count with max assets > $5B: 7706\n",
      "--count with max assets > $1B: 21165\n",
      "--count with max assets > $500M: 30545\n",
      "--count with max assets > $100M: 57750\n",
      "\n",
      "--sp500 count: 500\n",
      "sp500 : 500\n",
      "full : 98205\n",
      "$10B : 4692\n",
      "$5B : 7706\n",
      "$1B : 21165\n",
      "$500M : 30545\n",
      "$250M : 41927\n",
      "$100M : 57750\n",
      "done all\n"
     ]
    }
   ],
   "source": [
    "# Get the full factset universe of companies (primary issues) and the S&P500 subset\n",
    "\n",
    "factset_universe = pd.read_excel('/Users/joeybortfeld/Documents/CreditGradients Data/factset_primary_issue_universe.xlsx', skiprows=4)\n",
    "\n",
    "rename_dict = {'Sec is Primary Issue': 'ff_iscomp',\n",
    "               'Company': 'ff_co_name',\n",
    "               'FactSet Econ Sector': 'factset_econ_sector',\n",
    "               'FactSet Ind': 'factst_industry',\n",
    "               'Bus Desc': 'ff_bus_desc_ext',\n",
    "               'Entity ID': 'factset_entity_id',\n",
    "               'Entity Country HQ': 'factset_hq_country',\n",
    "               'Perm. Sec. ID': 'fsym_id',\n",
    "               'Max Assets (USD)': 'max_assets_in_usd',\n",
    "               'Exchange Couuntry Name': 'exchange_country',\n",
    "               'Exchange Ticker': 'exchange_ticker',\n",
    "               'Ult Parent ID': 'ultimate_parent_id',\n",
    "               'Primary Equity Listing': 'primary_equity_listing',\n",
    "               'P_SYMBOL': 'ticker'}\n",
    "\n",
    "factset_universe = factset_universe.rename(columns=rename_dict)\n",
    "factset_universe = factset_universe[factset_universe['fsym_id'] != '@NA']\n",
    "\n",
    "# sort largest to smallest by total assets (USD)\n",
    "factset_universe = factset_universe.sort_values(by='max_assets_in_usd', ascending=False)\n",
    "factset_universe = factset_universe.reset_index(drop=True)\n",
    "\n",
    "print('Total primary issue universe size:', len(factset_universe))\n",
    "\n",
    "print('--count with max assets > $10B:', len(factset_universe[factset_universe['max_assets_in_usd'] > 10_000]))\n",
    "print('--count with max assets > $5B:', len(factset_universe[factset_universe['max_assets_in_usd'] > 5_000]))\n",
    "print('--count with max assets > $1B:', len(factset_universe[factset_universe['max_assets_in_usd'] > 1_000]))\n",
    "print('--count with max assets > $500M:', len(factset_universe[factset_universe['max_assets_in_usd'] > 500]))\n",
    "print('--count with max assets > $100M:', len(factset_universe[factset_universe['max_assets_in_usd'] > 100]))\n",
    "\n",
    "print()\n",
    "\n",
    "################################################################################\n",
    "# get the S&P 500\n",
    "sp500_universe = pd.read_csv('/Users/joeybortfeld/Documents/CreditGradients Data/sp500_constituents.csv')\n",
    "sp500_universe['sp500'] = 1\n",
    "sp500_universe = sp500_universe.rename(columns={'Symbol': 'ticker'})\n",
    "sp500_universe = sp500_universe[['ticker', 'sp500']]\n",
    "\n",
    "# merge the two\n",
    "factset_universe = factset_universe.merge(sp500_universe, on='ticker', how='left')\n",
    "factset_universe['sp500'] = factset_universe['sp500'].fillna(0).astype(int)\n",
    "print('--sp500 count:', len(factset_universe[factset_universe['sp500'] == 1]))\n",
    "\n",
    "################################################################################\n",
    "# BUILD THE UNIVERSE SET AT VARIOUS ASSET THRESHOLDS\n",
    "universe_dict = {}\n",
    "\n",
    "# save the sp500 fsym_ids as a list\n",
    "temp = factset_universe[factset_universe['sp500'] == 1].copy()\n",
    "temp = temp[temp['fsym_id'] != '@NA']\n",
    "sp500_list = list(temp['fsym_id'])\n",
    "sp500_list = sorted(sp500_list)\n",
    "universe_dict['sp500'] = sp500_list\n",
    "\n",
    "# save the full universe fsym_ids as a list\n",
    "temp = factset_universe.copy()\n",
    "temp = temp[temp['fsym_id'] != '@NA']\n",
    "full_list = list(temp['fsym_id'].unique())\n",
    "universe_dict['full'] = full_list\n",
    "\n",
    "# save fsym_id universe at various asset thresholds\n",
    "for this_threshold in [('$10B', 10_000), ('$5B', 5_000), ('$1B', 1_000), ('$500M', 500), ('$250M', 250), ('$100M', 100)]:\n",
    "    temp = factset_universe[factset_universe['max_assets_in_usd'] > this_threshold[1]].copy()\n",
    "    temp = temp[temp['fsym_id'] != '@NA']\n",
    "    temp = temp['fsym_id'].unique()\n",
    "    temp = sorted(temp)\n",
    "    universe_dict[this_threshold[0]] = temp\n",
    "\n",
    "for k,v in universe_dict.items():\n",
    "    print(k,':', len(v))\n",
    "\n",
    "# save the semi-annual fsym_ids\n",
    "df_semi_annual = pd.read_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_semi_annual_fsym_id_list.csv')\n",
    "universe_dict['semi_annual'] = list(df_semi_annual['fsym_id'])\n",
    "\n",
    "# factset_universe.to_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_universe_processed.csv', index=False)\n",
    "\n",
    "print('done all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get the list of metrics in the Fundamentals API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_categories = [\n",
    "    'INCOME_STATEMENT',\n",
    "    'BALANCE_SHEET',\n",
    "    'CASH_FLOW',\n",
    "    'PENSION_AND_POSTRETIREMENT',\n",
    "    'MARKET_DATA',\n",
    "    'MISCELLANEOUS',\n",
    "    'DATES'\n",
    "]\n",
    "metrics_endpoint = 'https://api.factset.com/content/factset-fundamentals/v2/metrics'\n",
    "\n",
    "collection = []\n",
    "for this_category in metric_categories:\n",
    "\n",
    "    print(this_category)\n",
    "\n",
    "    metrics_request = {\"category\": this_category}\n",
    "    headers = {'Accept': 'application/json','Content-Type': 'application/json'}\n",
    "\n",
    "    #create a post request\n",
    "    metrics_post = json.dumps(metrics_request)\n",
    "    metrics_response = requests.get(url = metrics_endpoint, \n",
    "                                    data=metrics_post, \n",
    "                                    auth = authorization, \n",
    "                                    headers = headers, \n",
    "                                    verify= False )\n",
    "    print('HTTP Status: {}'.format(metrics_response.status_code))\n",
    "\n",
    "    #create a dataframe from POST request, show dataframe properties\n",
    "    metrics_data = json.loads(metrics_response.text)\n",
    "    metrics_df = pd.DataFrame(metrics_data['data'])\n",
    "    metrics_df['metric_category'] = this_category\n",
    "    print(metrics_df.shape)\n",
    "    \n",
    "    collection.append(metrics_df)\n",
    "\n",
    "metrics_df = pd.concat(collection, ignore_index=True)\n",
    "# metrics_df.to_csv('/Users/joeybortfeld/Documents/CreditGradients Data/all_fundamental_api_metrics_list.csv')\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fundamentals API Download - Assets in USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fundamentals API Download - All Metrics in Local Currency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = factset_api.batch_fundamental_download(fsym_list=universe_dict['full'],\n",
    "                               field_list=['FF_ASSETS'],\n",
    "                               currency='LOCAL',\n",
    "                               periodicity_list=['annual', 'quarterly' 'semi_annual'],\n",
    "                               start_date='1990-01-01',\n",
    "                               end_date='2024-12-31',\n",
    "                               skip_if_done=True,\n",
    "                               output_folder='/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_assets_in_usd/',\n",
    "                               factset_api_authorization=credentials.factset_api_authorization)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDIVIDUAL FSYM_ID DOWNLOAD METHOD\n",
    "\n",
    "# download parameters\n",
    "download_type_dict = {'annual': ['ANN', 20], \n",
    "                      'quarterly': ['QTR', 10],\n",
    "                      'semi_annual': ['SEMI', 15]}\n",
    "\n",
    "download_type = 'semi_annual'\n",
    "output_folder = f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_{download_type}/'\n",
    "start_date = '1990-01-01'\n",
    "end_date = '2024-12-31'\n",
    "skip_if_done = True\n",
    "\n",
    "################################################################################\n",
    "# define the company set\n",
    "company_set = universe_dict['$1B']\n",
    "if np.NaN in company_set:\n",
    "    company_set.remove(np.NaN)\n",
    "\n",
    "if download_type == 'semi_annual':\n",
    "    semi_annual_set = universe_dict['semi_annual']\n",
    "    company_set = [e for e in company_set if e in semi_annual_set]\n",
    "\n",
    "print('company set size:', len(company_set))\n",
    "\n",
    "# prescreen to see if the fsym_id is already in the output folder\n",
    "if skip_if_done:\n",
    "    print('--skipping files that are already done')\n",
    "    output_files = os.listdir(output_folder)\n",
    "    print('--file count in output folder:', len(output_files))\n",
    "    output_files = [e.replace('.csv', '') for e in output_files]    \n",
    "    company_set = [e for e in company_set if e not in output_files]\n",
    "\n",
    "    print('--new company set size when skipping:', len(company_set))\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# loop through fsym_ids\n",
    "error_list = []\n",
    "collection = []\n",
    "start_time = time.time()\n",
    "for this_fsym in tqdm.tqdm(company_set):\n",
    "\n",
    "    try:\n",
    "        result = utilities.download_fundamentals(id_list=[this_fsym],\n",
    "                                    field_list=fundamentals_var_list,\n",
    "                                    # field_list=['FF_ASSETS',],\n",
    "                                    periodicity=download_type_dict[download_type][0],\n",
    "                                    start_date=start_date,\n",
    "                                    end_date=end_date,\n",
    "                                    currency='LOCAL',\n",
    "                                    verbose=False,\n",
    "                                    authorization=authorization)\n",
    "        response_code, fundamentals_df = result\n",
    "\n",
    "        if response_code != 200:\n",
    "            error_list.append(this_fysm)\n",
    "            print('error:', this_fysm)\n",
    "        else:\n",
    "\n",
    "            fundamentals_df.to_csv(output_folder + f'{this_fsym}.csv', index=False)\n",
    "            collection.append(fundamentals_df)\n",
    "\n",
    "    except:\n",
    "        error_list.append(this_fsym)\n",
    "        print('error:', this_fsym)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "print('done in {}m'.format((time.time() - start_time) / 60))\n",
    "\n",
    "if len(error_list) > 0:\n",
    "    print('errors in download:', len(error_list))\n",
    "\n",
    "    \n",
    "\n",
    "else:\n",
    "    print('No errors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD ASSETS IN USD\n",
    "\n",
    "\n",
    "download_type_dict = {'annual': ['ANN', 20], \n",
    "                      'quarterly': ['QTR', 10],\n",
    "                      'semi_annual': ['SEMI', 15]}\n",
    "\n",
    "download_type = 'semi_annual'\n",
    "start_date = '1990-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "id_batches = batch_a_list(full_list, 30)\n",
    "error_list = []\n",
    "collection = []\n",
    "start_time = time.time()\n",
    "print('batch count:', len(id_batches))\n",
    "for counter, this_batch in enumerate(id_batches):\n",
    "\n",
    "    if counter % 250 == 0:\n",
    "        print(counter, datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    counter += 1\n",
    "\n",
    "    result = utilities.download_fundamentals(id_list=this_batch,\n",
    "                                    field_list=['FF_ASSETS'],\n",
    "                                    periodicity=download_type_dict[download_type][0],\n",
    "                                    start_date=start_date,\n",
    "                                    end_date=end_date,\n",
    "                                    currency='USD',\n",
    "                                    verbose=False,\n",
    "                                    authorization=authorization)\n",
    "    response_code, fundamentals_df = result\n",
    "\n",
    "    if response_code != 200:\n",
    "        error_list.append([counter,this_batch])\n",
    "    else:\n",
    "        fundamentals_df.to_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_{download_type}_assets_in_usd/fundamentals_df_{counter}.csv', index=False)\n",
    "        collection.append(fundamentals_df)\n",
    "\n",
    "print('done in {}m'.format((time.time() - start_time) / 60))\n",
    "if len(error_list) > 0:\n",
    "    print('errors in download:')\n",
    "    print(error_list)\n",
    "else:\n",
    "    print('No errors')\n",
    "\n",
    "# combine results into one dataframe\n",
    "df = pd.concat(collection, ignore_index=True)\n",
    "df.to_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_{download_type}_assets_in_usd/fundamentals_df_combined.csv', index=False)\n",
    "\n",
    "if download_type == 'semi_annual':\n",
    "\n",
    "    # save fsym_ids that report semi-annual data\n",
    "    temp = df[df['value'].notnull()]\n",
    "    temp = temp[temp['fsymId'] != '@NA']\n",
    "    temp['fsymId'].nunique()\n",
    "    temp = temp.drop_duplicates(subset=['fsymId'])\n",
    "    temp = temp[['fsymId']]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    temp.columns=['fsym_id']\n",
    "    temp.to_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_semi_annual_fsym_id_list.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PROCESSING\n",
    "df_annual = pd.read_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_annual/fundamentals_df_combined.csv')\n",
    "df_annual = utilities.preprocess_factset_fundamentals(df_annual, verbose=True)\n",
    "\n",
    "df_quarterly = pd.read_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_quarterly/fundamentals_df_combined.csv')\n",
    "df_quarterly = utilities.preprocess_factset_fundamentals(df_quarterly, verbose=True)\n",
    "\n",
    "df_semi_annual = pd.read_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_semi_annual/fundamentals_df_combined.csv')\n",
    "df_semi_annual = utilities.preprocess_factset_fundamentals(df_semi_annual, verbose=True)\n",
    "\n",
    "# check for any columns that are not in the flow or stock variable lists\n",
    "temp = [c for c in df_annual.columns if c not in utilities.flow_var_list + utilities.stock_var_list]    \n",
    "print('data validation:')\n",
    "print('non flow/stock vars:', temp)\n",
    "print()\n",
    "\n",
    "df_annual_formatted = utilities.format_annual_data(df_annual, \n",
    "                                         flow_vars=utilities.flow_var_list, \n",
    "                                         stock_vars=utilities.stock_var_list, \n",
    "                                         verbose=True)\n",
    "\n",
    "df_quarterly_formatted = utilities.format_quarterly_data(df_quarterly, \n",
    "                                              flow_vars=utilities.flow_var_list, \n",
    "                                              stock_vars=utilities.stock_var_list, \n",
    "                                              verbose=True) \n",
    "\n",
    "df_semi_annual_formatted = utilities.format_semi_annual_data(df_semi_annual, \n",
    "                                              flow_vars=utilities.flow_var_list, \n",
    "                                              stock_vars=utilities.stock_var_list, \n",
    "                                              verbose=True) \n",
    "\n",
    "df_merged = utilities.merge_quarterly_semi_and_annual(quarterly=df_quarterly_formatted, \n",
    "                                             semi_annual=df_semi_annual_formatted, \n",
    "                                             annual=df_annual_formatted, \n",
    "                                             flow_vars=utilities.flow_var_list, \n",
    "                                             stock_vars=utilities.stock_var_list, \n",
    "                                             cleanup=True)\n",
    "\n",
    "\n",
    "# construct ratios\n",
    "df = utilities.build_qml_model_ratios(df_merged, verbose=True)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('/Users/joeybortfeld/Downloads/Default list.csv')\n",
    "\n",
    "# collect all isins for each default\n",
    "temp1 = temp.groupby(['description', 'defaulttype1', 'defaultdate'])[['isin', 'cusip', 'ticker' ]].agg(lambda x: set(x))\n",
    "temp1 = temp1.reset_index()\n",
    "\n",
    "\n",
    "temp = temp.drop_duplicates(subset=['description', 'defaulttype1', 'defaultdate'])\n",
    "temp['first_default_date'] = temp.groupby(['description'])['defaultdate'].transform('min')\n",
    "temp = temp.sort_values(by=['first_default_date', 'description'])\n",
    "temp = temp.reset_index(drop=True)\n",
    "\n",
    "temp = temp[['description', 'defaulttype1', 'defaultdate', 'SectorLevel3', 'SectorLevel4', 'Commodity Sector']]\n",
    "temp = temp.merge(temp1, on=['description', 'defaulttype1', 'defaultdate'], how='left')\n",
    "\n",
    "temp.to_csv('/Users/joeybortfeld/Documents/CreditGradients Data/default_list_unique.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:04<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors\n"
     ]
    }
   ],
   "source": [
    "# Download company profile data\n",
    "\n",
    "company_set = universe_dict['full']\n",
    "if np.NaN in company_set:\n",
    "    company_set.remove(np.NaN)\n",
    "\n",
    "# error_list = []\n",
    "# collection = []\n",
    "error_list2 = []\n",
    "for this_fsym in tqdm.tqdm(error_list):\n",
    "\n",
    "    result = utilities.download_company_profile(id_list=[this_fsym,], authorization=authorization, verbose=False)\n",
    "    response_code, df = result\n",
    "    if response_code != 200:\n",
    "        error_list2.append(this_fsym)\n",
    "    else:\n",
    "        collection.append(df)\n",
    "\n",
    "if len(error_list2) > 0:\n",
    "    print('errors in download:', len(error_list2))\n",
    "\n",
    "else:\n",
    "    print('No errors')\n",
    "\n",
    "    df = pd.concat(collection, ignore_index=True)\n",
    "    df.to_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_company_profiles.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors in download: 26\n"
     ]
    }
   ],
   "source": [
    "print('errors in download:', len(error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>requestId</th>\n",
       "      <th>fsymId</th>\n",
       "      <th>FF_CO_NAME</th>\n",
       "      <th>FF_COUNTRY</th>\n",
       "      <th>FF_BUS_DESC_ABBREV</th>\n",
       "      <th>FF_BUS_DESC_EXT</th>\n",
       "      <th>FF_ISCOMP</th>\n",
       "      <th>FF_SECACT</th>\n",
       "      <th>FF_ACQ_DATE</th>\n",
       "      <th>FF_GEN_IND</th>\n",
       "      <th>FF_MAJOR_IND</th>\n",
       "      <th>FF_MAJOR_SUBIND</th>\n",
       "      <th>FF_MAJOR_IND_NAME</th>\n",
       "      <th>FF_MAJOR_SUBIND_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>Apple, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>Microsoft Corp.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Designs, manufactures smartphones, personal co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Develops, manufactures and distributes softwar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple, Inc. engages in the design, manufacture...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft Corp. engages in the development and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric requestId    fsymId       FF_CO_NAME     FF_COUNTRY  \\\n",
       "0        AAPL-US  MH33D6-R      Apple, Inc.            NaN   \n",
       "1        MSFT-US  P8R3C2-R  Microsoft Corp.            NaN   \n",
       "2        AAPL-US  MH33D6-R              NaN  UNITED STATES   \n",
       "3        MSFT-US  P8R3C2-R              NaN  UNITED STATES   \n",
       "4        AAPL-US  MH33D6-R              NaN            NaN   \n",
       "5        MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "6        AAPL-US  MH33D6-R              NaN            NaN   \n",
       "7        MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "8        AAPL-US  MH33D6-R              NaN            NaN   \n",
       "9        MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "10       AAPL-US  MH33D6-R              NaN            NaN   \n",
       "11       MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "12       AAPL-US  MH33D6-R              NaN            NaN   \n",
       "13       MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "14       AAPL-US  MH33D6-R              NaN            NaN   \n",
       "15       MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "16       AAPL-US  MH33D6-R              NaN            NaN   \n",
       "17       MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "18       AAPL-US  MH33D6-R              NaN            NaN   \n",
       "19       MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "20       AAPL-US  MH33D6-R              NaN            NaN   \n",
       "21       MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "22       AAPL-US  MH33D6-R              NaN            NaN   \n",
       "23       MSFT-US  P8R3C2-R              NaN            NaN   \n",
       "\n",
       "metric                                 FF_BUS_DESC_ABBREV  \\\n",
       "0                                                     NaN   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4       Designs, manufactures smartphones, personal co...   \n",
       "5       Develops, manufactures and distributes softwar...   \n",
       "6                                                     NaN   \n",
       "7                                                     NaN   \n",
       "8                                                     NaN   \n",
       "9                                                     NaN   \n",
       "10                                                    NaN   \n",
       "11                                                    NaN   \n",
       "12                                                    NaN   \n",
       "13                                                    NaN   \n",
       "14                                                    NaN   \n",
       "15                                                    NaN   \n",
       "16                                                    NaN   \n",
       "17                                                    NaN   \n",
       "18                                                    NaN   \n",
       "19                                                    NaN   \n",
       "20                                                    NaN   \n",
       "21                                                    NaN   \n",
       "22                                                    NaN   \n",
       "23                                                    NaN   \n",
       "\n",
       "metric                                    FF_BUS_DESC_EXT  FF_ISCOMP  \\\n",
       "0                                                     NaN        NaN   \n",
       "1                                                     NaN        NaN   \n",
       "2                                                     NaN        NaN   \n",
       "3                                                     NaN        NaN   \n",
       "4                                                     NaN        NaN   \n",
       "5                                                     NaN        NaN   \n",
       "6       Apple, Inc. engages in the design, manufacture...        NaN   \n",
       "7       Microsoft Corp. engages in the development and...        NaN   \n",
       "8                                                     NaN        1.0   \n",
       "9                                                     NaN        1.0   \n",
       "10                                                    NaN        NaN   \n",
       "11                                                    NaN        NaN   \n",
       "12                                                    NaN        NaN   \n",
       "13                                                    NaN        NaN   \n",
       "14                                                    NaN        NaN   \n",
       "15                                                    NaN        NaN   \n",
       "16                                                    NaN        NaN   \n",
       "17                                                    NaN        NaN   \n",
       "18                                                    NaN        NaN   \n",
       "19                                                    NaN        NaN   \n",
       "20                                                    NaN        NaN   \n",
       "21                                                    NaN        NaN   \n",
       "22                                                    NaN        NaN   \n",
       "23                                                    NaN        NaN   \n",
       "\n",
       "metric  FF_SECACT FF_ACQ_DATE FF_GEN_IND FF_MAJOR_IND FF_MAJOR_SUBIND  \\\n",
       "0             NaN         NaN        NaN          NaN             NaN   \n",
       "1             NaN         NaN        NaN          NaN             NaN   \n",
       "2             NaN         NaN        NaN          NaN             NaN   \n",
       "3             NaN         NaN        NaN          NaN             NaN   \n",
       "4             NaN         NaN        NaN          NaN             NaN   \n",
       "5             NaN         NaN        NaN          NaN             NaN   \n",
       "6             NaN         NaN        NaN          NaN             NaN   \n",
       "7             NaN         NaN        NaN          NaN             NaN   \n",
       "8             NaN         NaN        NaN          NaN             NaN   \n",
       "9             NaN         NaN        NaN          NaN             NaN   \n",
       "10            1.0         NaN        NaN          NaN             NaN   \n",
       "11            1.0         NaN        NaN          NaN             NaN   \n",
       "12            NaN        None        NaN          NaN             NaN   \n",
       "13            NaN        None        NaN          NaN             NaN   \n",
       "14            NaN         NaN         01          NaN             NaN   \n",
       "15            NaN         NaN         01          NaN             NaN   \n",
       "16            NaN         NaN        NaN         None             NaN   \n",
       "17            NaN         NaN        NaN         None             NaN   \n",
       "18            NaN         NaN        NaN          NaN            None   \n",
       "19            NaN         NaN        NaN          NaN            None   \n",
       "20            NaN         NaN        NaN          NaN             NaN   \n",
       "21            NaN         NaN        NaN          NaN             NaN   \n",
       "22            NaN         NaN        NaN          NaN             NaN   \n",
       "23            NaN         NaN        NaN          NaN             NaN   \n",
       "\n",
       "metric FF_MAJOR_IND_NAME FF_MAJOR_SUBIND_NAME  \n",
       "0                    NaN                  NaN  \n",
       "1                    NaN                  NaN  \n",
       "2                    NaN                  NaN  \n",
       "3                    NaN                  NaN  \n",
       "4                    NaN                  NaN  \n",
       "5                    NaN                  NaN  \n",
       "6                    NaN                  NaN  \n",
       "7                    NaN                  NaN  \n",
       "8                    NaN                  NaN  \n",
       "9                    NaN                  NaN  \n",
       "10                   NaN                  NaN  \n",
       "11                   NaN                  NaN  \n",
       "12                   NaN                  NaN  \n",
       "13                   NaN                  NaN  \n",
       "14                   NaN                  NaN  \n",
       "15                   NaN                  NaN  \n",
       "16                   NaN                  NaN  \n",
       "17                   NaN                  NaN  \n",
       "18                   NaN                  NaN  \n",
       "19                   NaN                  NaN  \n",
       "20                  None                  NaN  \n",
       "21                  None                  NaN  \n",
       "22                   NaN                 None  \n",
       "23                   NaN                 None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download fundamentals descriptive data\n",
    "\n",
    "descriptive_var_list = [\n",
    "    'FF_CO_NAME',\n",
    "\n",
    "    'FF_COUNTRY',\n",
    "\n",
    "    'FF_BUS_DESC_ABBREV',\n",
    "    'FF_BUS_DESC_EXT',\n",
    "    \n",
    "    'FF_ISCOMP',\n",
    "    'FF_SECACT',\n",
    "    'FF_ACQ_DATE',\n",
    "\n",
    "    'FF_GEN_IND', \n",
    "    'FF_MAJOR_IND',\n",
    "    'FF_MAJOR_SUBIND',\n",
    "\n",
    "  'FF_MAJOR_IND_NAME',\n",
    "  'FF_MAJOR_SUBIND_NAME']\n",
    "collection = []\n",
    "for this_metric in [[e] for e in descriptive_var_list]:\n",
    "\n",
    "  fundamentals_endpoint = 'https://api.factset.com/content/factset-fundamentals/v2/fundamentals'\n",
    "  fundamentals_request_2={\n",
    "    \"data\": {\n",
    "      \"ids\": ['AAPL-US', 'MSFT-US'],\n",
    "      \"metrics\": this_metric\n",
    "    }\n",
    "  }\n",
    "  headers = {'Accept': 'application/json','Content-Type': 'application/json'}\n",
    "\n",
    "  #create a post request\n",
    "  fundamentals_post = json.dumps(fundamentals_request_2)\n",
    "  # print('POST request:')\n",
    "  # print(fundamentals_endpoint)\n",
    "  # print(fundamentals_post)\n",
    "  # print()\n",
    "\n",
    "  fundamentals_response = requests.post(url = fundamentals_endpoint, \n",
    "                                        data=fundamentals_post, \n",
    "                                        auth = authorization, \n",
    "                                        headers = headers, \n",
    "                                        verify= False )\n",
    "  # print('HTTP Status: {}'.format(fundamentals_response.status_code))\n",
    "\n",
    "  # create a dataframe from POST request, show dataframe properties\n",
    "  fundamentals_data = json.loads(fundamentals_response.text)\n",
    "  if fundamentals_response.status_code != 200:\n",
    "    print(fundamentals_data)\n",
    "  else:\n",
    "    df = pd.DataFrame(fundamentals_data['data'])\n",
    "    # print('RECORDS:',len(fundamentals_df))\n",
    "    # print(fundamentals_df[['metric', 'value']].head(20))\n",
    "    df = df.pivot(index=['requestId', 'fsymId'], columns='metric', values='value')\n",
    "    df.reset_index(inplace=True)\n",
    "    collection.append(df)\n",
    "\n",
    "df = pd.concat(collection, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requestId</th>\n",
       "      <th>fsymId</th>\n",
       "      <th>tickerRegion</th>\n",
       "      <th>name</th>\n",
       "      <th>exchange</th>\n",
       "      <th>address</th>\n",
       "      <th>economyId</th>\n",
       "      <th>economy</th>\n",
       "      <th>sectorId</th>\n",
       "      <th>sector</th>\n",
       "      <th>...</th>\n",
       "      <th>subIndustryId</th>\n",
       "      <th>subIndustry</th>\n",
       "      <th>numberOfEmployees</th>\n",
       "      <th>ceo</th>\n",
       "      <th>businessSummary</th>\n",
       "      <th>yearFounded</th>\n",
       "      <th>marketCapitalization</th>\n",
       "      <th>totalMarketCapitalization</th>\n",
       "      <th>sharesOutstanding</th>\n",
       "      <th>peRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>Microsoft Corp.</td>\n",
       "      <td>{'exchangeId': 'NAS', 'fullName': 'NASDAQ'}</td>\n",
       "      <td>{'streetLine1': 'One Microsoft Way', 'city': '...</td>\n",
       "      <td>55</td>\n",
       "      <td>Technology</td>\n",
       "      <td>5520</td>\n",
       "      <td>Software and Consulting</td>\n",
       "      <td>...</td>\n",
       "      <td>552015401010</td>\n",
       "      <td>General and Mixed-Type Software</td>\n",
       "      <td>228000</td>\n",
       "      <td>Mr. Satya Nadella</td>\n",
       "      <td>Microsoft Corp. engages in the development and...</td>\n",
       "      <td>1975</td>\n",
       "      <td>3085475200000</td>\n",
       "      <td>3085475500000</td>\n",
       "      <td>7434880000</td>\n",
       "      <td>34.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>Apple, Inc.</td>\n",
       "      <td>{'exchangeId': 'NAS', 'fullName': 'NASDAQ'}</td>\n",
       "      <td>{'streetLine1': 'One Apple Park Way', 'city': ...</td>\n",
       "      <td>55</td>\n",
       "      <td>Technology</td>\n",
       "      <td>5515</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>...</td>\n",
       "      <td>551515453010</td>\n",
       "      <td>Smart Phone Manufacturing</td>\n",
       "      <td>164000</td>\n",
       "      <td>Mr. Timothy Donald Cook</td>\n",
       "      <td>Apple, Inc. engages in the design, manufacture...</td>\n",
       "      <td>1976</td>\n",
       "      <td>3401055000000</td>\n",
       "      <td>3401060250000</td>\n",
       "      <td>15115800000</td>\n",
       "      <td>36.9847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  requestId    fsymId tickerRegion             name  \\\n",
       "0   MSFT-US  P8R3C2-R      MSFT-US  Microsoft Corp.   \n",
       "1   AAPL-US  MH33D6-R      AAPL-US      Apple, Inc.   \n",
       "\n",
       "                                      exchange  \\\n",
       "0  {'exchangeId': 'NAS', 'fullName': 'NASDAQ'}   \n",
       "1  {'exchangeId': 'NAS', 'fullName': 'NASDAQ'}   \n",
       "\n",
       "                                             address economyId     economy  \\\n",
       "0  {'streetLine1': 'One Microsoft Way', 'city': '...        55  Technology   \n",
       "1  {'streetLine1': 'One Apple Park Way', 'city': ...        55  Technology   \n",
       "\n",
       "  sectorId                   sector  ... subIndustryId  \\\n",
       "0     5520  Software and Consulting  ...  552015401010   \n",
       "1     5515                 Hardware  ...  551515453010   \n",
       "\n",
       "                       subIndustry numberOfEmployees                      ceo  \\\n",
       "0  General and Mixed-Type Software            228000        Mr. Satya Nadella   \n",
       "1        Smart Phone Manufacturing            164000  Mr. Timothy Donald Cook   \n",
       "\n",
       "                                     businessSummary yearFounded  \\\n",
       "0  Microsoft Corp. engages in the development and...        1975   \n",
       "1  Apple, Inc. engages in the design, manufacture...        1976   \n",
       "\n",
       "  marketCapitalization totalMarketCapitalization  sharesOutstanding  peRatio  \n",
       "0        3085475200000             3085475500000         7434880000  34.2525  \n",
       "1        3401055000000             3401060250000        15115800000  36.9847  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = 'https://api.factset.com/content/factset-fundamentals/v2/company-reports/profile?ids=AAPL-US,MSFT-US'\n",
    "\n",
    "request={\n",
    "    'data': {\n",
    "        \"ids\": [\"AAPL-US\"],\n",
    "    }\n",
    "  }\n",
    "\n",
    "\n",
    "headers = {'Accept': 'application/json','Content-Type': 'application/json'}\n",
    "post = json.dumps(request)\n",
    "response = requests.get(url = endpoint, auth = authorization, headers = headers, verify= False )\n",
    "temp = pd.DataFrame(json.loads(response.text)['data'])\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requestId</th>\n",
       "      <th>fsymId</th>\n",
       "      <th>tickerRegion</th>\n",
       "      <th>name</th>\n",
       "      <th>exchange</th>\n",
       "      <th>address</th>\n",
       "      <th>economyId</th>\n",
       "      <th>economy</th>\n",
       "      <th>sectorId</th>\n",
       "      <th>sector</th>\n",
       "      <th>...</th>\n",
       "      <th>subIndustryId</th>\n",
       "      <th>subIndustry</th>\n",
       "      <th>numberOfEmployees</th>\n",
       "      <th>ceo</th>\n",
       "      <th>businessSummary</th>\n",
       "      <th>yearFounded</th>\n",
       "      <th>marketCapitalization</th>\n",
       "      <th>totalMarketCapitalization</th>\n",
       "      <th>sharesOutstanding</th>\n",
       "      <th>peRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>Apple, Inc.</td>\n",
       "      <td>{'exchangeId': 'NAS', 'fullName': 'NASDAQ'}</td>\n",
       "      <td>{'streetLine1': 'One Apple Park Way', 'city': ...</td>\n",
       "      <td>55</td>\n",
       "      <td>Technology</td>\n",
       "      <td>5515</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>...</td>\n",
       "      <td>551515453010</td>\n",
       "      <td>Smart Phone Manufacturing</td>\n",
       "      <td>164000</td>\n",
       "      <td>Mr. Timothy Donald Cook</td>\n",
       "      <td>Apple, Inc. engages in the design, manufacture...</td>\n",
       "      <td>1976</td>\n",
       "      <td>3461518200000</td>\n",
       "      <td>3461523500000</td>\n",
       "      <td>15115800000</td>\n",
       "      <td>37.6422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>Microsoft Corp.</td>\n",
       "      <td>{'exchangeId': 'NAS', 'fullName': 'NASDAQ'}</td>\n",
       "      <td>{'streetLine1': 'One Microsoft Way', 'city': '...</td>\n",
       "      <td>55</td>\n",
       "      <td>Technology</td>\n",
       "      <td>5520</td>\n",
       "      <td>Software and Consulting</td>\n",
       "      <td>...</td>\n",
       "      <td>552015401010</td>\n",
       "      <td>General and Mixed-Type Software</td>\n",
       "      <td>228000</td>\n",
       "      <td>Mr. Satya Nadella</td>\n",
       "      <td>Microsoft Corp. engages in the development and...</td>\n",
       "      <td>1975</td>\n",
       "      <td>3089118291200</td>\n",
       "      <td>3089118500000</td>\n",
       "      <td>7434880000</td>\n",
       "      <td>34.2930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  requestId    fsymId tickerRegion             name  \\\n",
       "0   AAPL-US  MH33D6-R      AAPL-US      Apple, Inc.   \n",
       "1   MSFT-US  P8R3C2-R      MSFT-US  Microsoft Corp.   \n",
       "\n",
       "                                      exchange  \\\n",
       "0  {'exchangeId': 'NAS', 'fullName': 'NASDAQ'}   \n",
       "1  {'exchangeId': 'NAS', 'fullName': 'NASDAQ'}   \n",
       "\n",
       "                                             address economyId     economy  \\\n",
       "0  {'streetLine1': 'One Apple Park Way', 'city': ...        55  Technology   \n",
       "1  {'streetLine1': 'One Microsoft Way', 'city': '...        55  Technology   \n",
       "\n",
       "  sectorId                   sector  ... subIndustryId  \\\n",
       "0     5515                 Hardware  ...  551515453010   \n",
       "1     5520  Software and Consulting  ...  552015401010   \n",
       "\n",
       "                       subIndustry numberOfEmployees                      ceo  \\\n",
       "0        Smart Phone Manufacturing            164000  Mr. Timothy Donald Cook   \n",
       "1  General and Mixed-Type Software            228000        Mr. Satya Nadella   \n",
       "\n",
       "                                     businessSummary yearFounded  \\\n",
       "0  Apple, Inc. engages in the design, manufacture...        1976   \n",
       "1  Microsoft Corp. engages in the development and...        1975   \n",
       "\n",
       "  marketCapitalization totalMarketCapitalization  sharesOutstanding  peRatio  \n",
       "0        3461518200000             3461523500000        15115800000  37.6422  \n",
       "1        3089118291200             3089118500000         7434880000  34.2930  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = ['AAPL-US', 'MSFT-US']\n",
    "endpoint = 'https://api.factset.com/content/factset-fundamentals/v2/company-reports/profile?ids=' + ','.join(id_list)\n",
    "headers = {'Accept': 'application/json','Content-Type': 'application/json'}\n",
    "response = requests.get(url = endpoint, auth = authorization, headers = headers, verify= False )\n",
    "temp = pd.DataFrame(json.loads(response.text)['data'])\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.factset.com/content/factset-fundamentals/v2/company-reports/profile?ids=MH33D6-R,MSFT-US\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requestId</th>\n",
       "      <th>fsymId</th>\n",
       "      <th>tickerRegion</th>\n",
       "      <th>name</th>\n",
       "      <th>exchange</th>\n",
       "      <th>address</th>\n",
       "      <th>economyId</th>\n",
       "      <th>economy</th>\n",
       "      <th>sectorId</th>\n",
       "      <th>sector</th>\n",
       "      <th>...</th>\n",
       "      <th>subIndustryId</th>\n",
       "      <th>subIndustry</th>\n",
       "      <th>numberOfEmployees</th>\n",
       "      <th>ceo</th>\n",
       "      <th>businessSummary</th>\n",
       "      <th>yearFounded</th>\n",
       "      <th>marketCapitalization</th>\n",
       "      <th>totalMarketCapitalization</th>\n",
       "      <th>sharesOutstanding</th>\n",
       "      <th>peRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>P8R3C2-R</td>\n",
       "      <td>MSFT-US</td>\n",
       "      <td>Microsoft Corp.</td>\n",
       "      <td>{'exchangeId': 'NAS', 'fullName': 'NASDAQ'}</td>\n",
       "      <td>{'streetLine1': 'One Microsoft Way', 'city': '...</td>\n",
       "      <td>55</td>\n",
       "      <td>Technology</td>\n",
       "      <td>5520</td>\n",
       "      <td>Software and Consulting</td>\n",
       "      <td>...</td>\n",
       "      <td>552015401010</td>\n",
       "      <td>General and Mixed-Type Software</td>\n",
       "      <td>228000</td>\n",
       "      <td>Mr. Satya Nadella</td>\n",
       "      <td>Microsoft Corp. engages in the development and...</td>\n",
       "      <td>1975</td>\n",
       "      <td>3085475200000</td>\n",
       "      <td>3085475500000</td>\n",
       "      <td>7434880000</td>\n",
       "      <td>34.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>AAPL-US</td>\n",
       "      <td>Apple, Inc.</td>\n",
       "      <td>{'exchangeId': 'NAS', 'fullName': 'NASDAQ'}</td>\n",
       "      <td>{'streetLine1': 'One Apple Park Way', 'city': ...</td>\n",
       "      <td>55</td>\n",
       "      <td>Technology</td>\n",
       "      <td>5515</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>...</td>\n",
       "      <td>551515453010</td>\n",
       "      <td>Smart Phone Manufacturing</td>\n",
       "      <td>164000</td>\n",
       "      <td>Mr. Timothy Donald Cook</td>\n",
       "      <td>Apple, Inc. engages in the design, manufacture...</td>\n",
       "      <td>1976</td>\n",
       "      <td>3401055000000</td>\n",
       "      <td>3401060250000</td>\n",
       "      <td>15115800000</td>\n",
       "      <td>36.9847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  requestId    fsymId tickerRegion             name  \\\n",
       "0   MSFT-US  P8R3C2-R      MSFT-US  Microsoft Corp.   \n",
       "1  MH33D6-R  MH33D6-R      AAPL-US      Apple, Inc.   \n",
       "\n",
       "                                      exchange  \\\n",
       "0  {'exchangeId': 'NAS', 'fullName': 'NASDAQ'}   \n",
       "1  {'exchangeId': 'NAS', 'fullName': 'NASDAQ'}   \n",
       "\n",
       "                                             address economyId     economy  \\\n",
       "0  {'streetLine1': 'One Microsoft Way', 'city': '...        55  Technology   \n",
       "1  {'streetLine1': 'One Apple Park Way', 'city': ...        55  Technology   \n",
       "\n",
       "  sectorId                   sector  ... subIndustryId  \\\n",
       "0     5520  Software and Consulting  ...  552015401010   \n",
       "1     5515                 Hardware  ...  551515453010   \n",
       "\n",
       "                       subIndustry numberOfEmployees                      ceo  \\\n",
       "0  General and Mixed-Type Software            228000        Mr. Satya Nadella   \n",
       "1        Smart Phone Manufacturing            164000  Mr. Timothy Donald Cook   \n",
       "\n",
       "                                     businessSummary yearFounded  \\\n",
       "0  Microsoft Corp. engages in the development and...        1975   \n",
       "1  Apple, Inc. engages in the design, manufacture...        1976   \n",
       "\n",
       "  marketCapitalization totalMarketCapitalization  sharesOutstanding  peRatio  \n",
       "0        3085475200000             3085475500000         7434880000  34.2525  \n",
       "1        3401055000000             3401060250000        15115800000  36.9847  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers = {'Accept': 'application/json','Content-Type': 'application/json'}\n",
    "\n",
    "#create a post request\n",
    "fundamentals_post_3 = json.dumps(fundamentals_request_3)\n",
    "fundamentals_response_3 = requests.post(url = fundamentals_endpoint, data=fundamentals_post_3, auth = authorization, headers = headers, verify= False )\n",
    "print('HTTP Status: {}'.format(fundamentals_response_3.status_code))\n",
    "\n",
    "#create a dataframe from POST request, show dataframe properties\n",
    "fundamentals_data_3 = json.loads(fundamentals_response_3.text)\n",
    "# fundamentals_df_3 = json_normalize(fundamentals_data_3['data'])\n",
    "fundamentals_df_3 = pd.DataFrame(fundamentals_data_3['data'])\n",
    "print('COLUMNS:')\n",
    "print('')\n",
    "print(fundamentals_df_3.dtypes)\n",
    "print('')\n",
    "print('RECORDS:',len(fundamentals_df_3))\n",
    "\n",
    "#show the last 5 records for select columns\n",
    "fundamentals_df_3[['requestId','fsymId','metric','periodicity','fiscalPeriod','periodicity','fiscalYear','fiscalPeriodLength','fiscalEndDate','reportDate','epsReportDate','updateType','currency','value']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file = 's3://qml-solutions-new-york/factset-api-fundamentals-annual/fundamentals_df_0.csv'\n",
    "temp = pd.read_csv(file, storage_options=aws_credentials)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONVERSION FROM BATCHES TO SINGLE FSYM_ID PER FILE\n",
    "\n",
    "counter = 0\n",
    "for i in range(1,3275):\n",
    "\n",
    "    if counter % 250 == 0:\n",
    "        print(counter, datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    file = f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_semi_annual_assets_in_usdX/fundamentals_df_{i}.csv'\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    fsym_ids = list(df['fsymId'].unique())\n",
    "    for fsym_id in fsym_ids:\n",
    "        df[df['fsymId'] == fsym_id].to_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_semi_annual_assets_in_usd/{fsym_id}.csv', index=False)\n",
    "\n",
    "    counter += 1    \n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECT ASSETS IN USD\n",
    "df = pd.read_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_annual_assets_in_usd/fundamentals_df_combined.csv')\n",
    "print(df.columns)\n",
    "print(df['fsymId'].nunique())\n",
    "\n",
    "fsfsd\n",
    "\n",
    "df = df[df['fsymId'] != '@NA']\n",
    "df = df[df['value'].notnull()]\n",
    "df = df.sort_values(by=['fsymId', 'value'], ascending=[True, False])\n",
    "df = df.drop_duplicates(subset=['fsymId'], keep='first')\n",
    "df = df.sort_values(by='value', ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df = df[['fsymId', 'currency', 'fiscalEndDate', 'value']]\n",
    "df.to_csv('/Users/joeybortfeld/Downloads/temp.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EQUITY DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to /Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_returns/\n",
      "company set size: 21165\n",
      "--skipping files that are already done\n",
      "--file count in output folder: 1698\n",
      "--new company set size when skipping: 19467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19467/19467 [2:13:39<00:00,  2.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 133.66318048238753m\n",
      "No errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# INDIVIDUAL FSYM_ID DOWNLOAD METHOD\n",
    "\n",
    "metric = 'returns' # either 'prices' or 'returns'\n",
    "split = 'SPLIT'\n",
    "start_date = '2006-01-03'\n",
    "end_date = '2024-11-12'\n",
    "skip_if_done = True\n",
    "\n",
    "assert metric in ['prices', 'returns'], 'error: metric must be either price or return'\n",
    "\n",
    "if metric == 'prices':\n",
    "    output_folder = f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices_{split.lower()}/'\n",
    "else:\n",
    "    output_folder = f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_returns/'\n",
    "print('writing to', output_folder)\n",
    "\n",
    "################################################################################\n",
    "# define the company set\n",
    "company_set = universe_dict['$1B']\n",
    "if np.NaN in company_set:\n",
    "    company_set.remove(np.NaN)\n",
    "print('company set size:', len(company_set))\n",
    "\n",
    "# prescreen to see if the fsym_id is already in the output folder\n",
    "if skip_if_done:\n",
    "    print('--skipping files that are already done')\n",
    "    output_files = os.listdir(output_folder)\n",
    "    print('--file count in output folder:', len(output_files))\n",
    "    output_files = [e.replace('.csv', '') for e in output_files]    \n",
    "    company_set = [e for e in company_set if e not in output_files]\n",
    "\n",
    "    print('--new company set size when skipping:', len(company_set))\n",
    "################################################################################\n",
    "\n",
    "# loop through fsym_ids\n",
    "error_list = []\n",
    "collection = []\n",
    "start_time = time.time()\n",
    "for this_fsym in tqdm.tqdm(company_set):\n",
    "\n",
    "    try:\n",
    "        if metric == 'prices':\n",
    "            result = utilities.get_stock_prices(id_list=[this_fsym],\n",
    "                                        field_list=[\"price\", \"volume\", \"tradeCount\"],\n",
    "                                        start_date=start_date,\n",
    "                                        end_date=end_date,\n",
    "                                        frequency='D',\n",
    "                                        verbose=False, \n",
    "                                        split=split,\n",
    "                                        authorization=authorization)\n",
    "        else:\n",
    "            result = utilities.get_stock_returns(id_list=[this_fsym],\n",
    "                                        start_date=start_date,\n",
    "                                        end_date=end_date,\n",
    "                                        frequency='D',\n",
    "                                        verbose=False, \n",
    "                                        authorization=authorization)\n",
    "        response_code, this_df = result\n",
    "\n",
    "        if response_code != 200:\n",
    "            error_list.append(this_fysm)\n",
    "            # print('error:', this_fysm)\n",
    "        else:\n",
    "\n",
    "            this_df.to_csv(output_folder + f'{this_fsym}.csv', index=False)\n",
    "            # collection.append(this_df)\n",
    "\n",
    "    except:\n",
    "        error_list.append(this_fsym)\n",
    "        print('error:', this_fsym)\n",
    "\n",
    "print('done in {}m'.format((time.time() - start_time) / 60))\n",
    "\n",
    "if len(error_list) > 0:\n",
    "    print('errors in download:')\n",
    "    print(len(error_list))\n",
    "    print(error_list)\n",
    "else:\n",
    "    print('No errors')\n",
    "\n",
    "# df = pd.concat(collection, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200,\n",
       "          volume        date  tradeCount requestId   price    fsymId currency\n",
       " 0           NaN  2024-01-01         NaN  MH33D6-R     NaN  MH33D6-R     None\n",
       " 1    82488674.0  2024-01-02   1008879.0  MH33D6-R  185.64  MH33D6-R      USD\n",
       " 2    58414460.0  2024-01-03    656857.0  MH33D6-R  184.25  MH33D6-R      USD\n",
       " 3    71983570.0  2024-01-04    712698.0  MH33D6-R  181.91  MH33D6-R      USD\n",
       " 4    62379661.0  2024-01-05    682339.0  MH33D6-R  181.18  MH33D6-R      USD\n",
       " ..          ...         ...         ...       ...     ...       ...      ...\n",
       " 214  38802304.0  2024-10-25    551685.0  MH33D6-R  231.41  MH33D6-R      USD\n",
       " 215  36087134.0  2024-10-28    557150.0  MH33D6-R  233.40  MH33D6-R      USD\n",
       " 216  35417247.0  2024-10-29    484098.0  MH33D6-R  233.67  MH33D6-R      USD\n",
       " 217  47070907.0  2024-10-30    593657.0  MH33D6-R  230.10  MH33D6-R      USD\n",
       " 218  64370086.0  2024-10-31    767900.0  MH33D6-R  225.91  MH33D6-R      USD\n",
       " \n",
       " [219 rows x 7 columns]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = utilities.get_stock_prices(id_list=['MH33D6-R'],\n",
    "                                        field_list=[\"price\", \"volume\", \"tradeCount\"],\n",
    "                                        start_date='2024-01-01',\n",
    "                                        end_date='2024-10-31',\n",
    "                                        frequency='D',\n",
    "                                        verbose=False, \n",
    "                                        split='SPLIT',\n",
    "                                        authorization=authorization)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to /Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_shares_outstanding_quarterly/\n",
      "company set size: 21165\n",
      "--skipping files that are already done\n",
      "--file count in output folder: 293\n",
      "--new company set size when skipping: 20872\n",
      "start time: 13:12:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20872/20872 [1:37:17<00:00,  3.58it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 97.28639477888743m\n",
      "No errors\n",
      "end time: 14:49:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# INDIVIDUAL FSYM_ID DOWNLOAD METHOD - SHARES OUTSTANDING\n",
    "\n",
    "# download parameters\n",
    "download_type_dict = {'annual': ['ANN', 20], \n",
    "                      'quarterly': ['QTR', 10],\n",
    "                      'semi_annual': ['SEMI', 15]}\n",
    "\n",
    "download_type = 'quarterly'\n",
    "output_folder = f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_fundamentals_shares_outstanding_{download_type}/'\n",
    "start_date = '1990-01-01'\n",
    "end_date = '2024-12-31'\n",
    "skip_if_done = True\n",
    "\n",
    "print('writing to', output_folder)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# define the company set\n",
    "company_set = universe_dict['$1B']\n",
    "if np.NaN in company_set:\n",
    "    company_set.remove(np.NaN)\n",
    "\n",
    "if download_type == 'semi_annual':\n",
    "    semi_annual_set = universe_dict['semi_annual']\n",
    "    company_set = [e for e in company_set if e in semi_annual_set]\n",
    "\n",
    "print('company set size:', len(company_set))\n",
    "\n",
    "# prescreen to see if the fsym_id is already in the output folder\n",
    "if skip_if_done:\n",
    "    print('--skipping files that are already done')\n",
    "    output_files = os.listdir(output_folder)\n",
    "    print('--file count in output folder:', len(output_files))\n",
    "    output_files = [e.replace('.csv', '') for e in output_files]    \n",
    "    company_set = [e for e in company_set if e not in output_files]\n",
    "\n",
    "    print('--new company set size when skipping:', len(company_set))\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# loop through fsym_ids\n",
    "error_list = []\n",
    "collection = []\n",
    "start_time = time.time()\n",
    "print('start time:', datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "for this_fsym in tqdm.tqdm(company_set):\n",
    "\n",
    "    try:\n",
    "        result = utilities.download_fundamentals(id_list=[this_fsym],\n",
    "                                    field_list=['FF_COM_SHS_OUT',],\n",
    "                                    periodicity=download_type_dict[download_type][0],\n",
    "                                    start_date=start_date,\n",
    "                                    end_date=end_date,\n",
    "                                    currency='LOCAL',\n",
    "                                    verbose=False,\n",
    "                                    authorization=authorization)\n",
    "        response_code, fundamentals_df = result\n",
    "\n",
    "        if response_code != 200:\n",
    "            error_list.append(this_fysm)\n",
    "            print('error:', this_fysm)\n",
    "        else:\n",
    "\n",
    "            fundamentals_df.to_csv(output_folder + f'{this_fsym}.csv', index=False)\n",
    "            collection.append(fundamentals_df)\n",
    "\n",
    "    except:\n",
    "        error_list.append(this_fsym)\n",
    "        print('error:', this_fsym)\n",
    "\n",
    "print('done in {}m'.format((time.time() - start_time) / 60))\n",
    "\n",
    "if len(error_list) > 0:\n",
    "    print('errors in download:')\n",
    "    print(error_list)\n",
    "else:\n",
    "    print('No errors')\n",
    "print('end time:', datetime.datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE PUBLIC UNIVERSE\n",
    "# these are companies where we have a price\n",
    "\n",
    "output_dir = '/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices_split/'\n",
    "file_list = os.listdir(output_dir)\n",
    "file_list = [f for f in file_list if f.endswith('.csv')]\n",
    "\n",
    "print(f'There are {len(file_list)} files in the directory')\n",
    "\n",
    "collection = []\n",
    "for f in tqdm.tqdm(file_list):\n",
    "    df = pd.read_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices_split/{f}')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df[['fsymId', 'date', 'price']]\n",
    "    df = df[df['price'].notnull()]\n",
    "    min_date  = df['date'].min()\n",
    "    max_date = df['date'].max()\n",
    "    collection.append([f.replace('.csv', ''), min_date, max_date])\n",
    "\n",
    "df = pd.DataFrame(collection, columns=['fsym_id', 'min_date', 'max_date'])\n",
    "df['min_date'] = pd.to_datetime(df['min_date'])\n",
    "df['max_date'] = pd.to_datetime(df['max_date'])\n",
    "\n",
    "df.to_csv('/Users/joeybortfeld/Documents/CreditGradients Data/factset_public_universe_with_assets_greater_than_1_billion_usd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MONTH END STOCK PRICES HISTORY\n",
    "\n",
    "input_dir = '/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices_split/'\n",
    "output_dir = '/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices_split_month_end/'\n",
    "file_list = os.listdir(input_dir)\n",
    "file_list = [f for f in file_list if f.endswith('.csv')]\n",
    "\n",
    "print(f'There are {len(file_list)} files in the directory')\n",
    "\n",
    "collection = []\n",
    "for f in tqdm.tqdm(file_list):\n",
    "    df = pd.read_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices_split/{f}')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "\n",
    "    df = df[df['price'].notnull()]\n",
    "\n",
    "    # only keep the month end prices (not exactly month end, if a stock only trades on the 10th of the month, it will be included)\n",
    "    df['max_date'] = df.groupby(['fsymId', 'year', 'month'])['date'].transform('max')\n",
    "    df = df[df['date'] == df['max_date']]\n",
    "    \n",
    "    df = df[['fsymId', 'currency', 'year', 'month', 'date', 'price']]\n",
    "\n",
    "    \n",
    "\n",
    "    df.to_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices_split_month_end/{f}', index=False)\n",
    "\n",
    "\n",
    "    # save to /Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices_month_end/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeybortfeld/Documents/CreditGradients/code/Factset Tutorials/utilities.py:857: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['shares_outstanding'] = df['shares_outstanding'].fillna(method='ffill', limit=ffill_limit_dict[market_cap_type])   # allow 12 months of fill forward (12 row) plut 4 more rows for quarterly financial filings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fsym_id</th>\n",
       "      <th>market_cap_date</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>price</th>\n",
       "      <th>shares_outstanding</th>\n",
       "      <th>market_cap_currency</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.677497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.656426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2006-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.724997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.716069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.887854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>3.366811e+06</td>\n",
       "      <td>222.720000</td>\n",
       "      <td>15116.786</td>\n",
       "      <td>USD</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>3.438766e+06</td>\n",
       "      <td>227.480000</td>\n",
       "      <td>15116.786</td>\n",
       "      <td>USD</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>3.430906e+06</td>\n",
       "      <td>226.960000</td>\n",
       "      <td>15116.786</td>\n",
       "      <td>USD</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>3.389637e+06</td>\n",
       "      <td>224.230000</td>\n",
       "      <td>15116.786</td>\n",
       "      <td>USD</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>MH33D6-R</td>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>3.389637e+06</td>\n",
       "      <td>224.230000</td>\n",
       "      <td>15116.786</td>\n",
       "      <td>USD</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4747 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fsym_id market_cap_date    market_cap       price  shares_outstanding  \\\n",
       "0     MH33D6-R      2006-01-04           NaN    2.677497                 NaN   \n",
       "1     MH33D6-R      2006-01-05           NaN    2.656426                 NaN   \n",
       "2     MH33D6-R      2006-01-06           NaN    2.724997                 NaN   \n",
       "3     MH33D6-R      2006-01-09           NaN    2.716069                 NaN   \n",
       "4     MH33D6-R      2006-01-10           NaN    2.887854                 NaN   \n",
       "...        ...             ...           ...         ...                 ...   \n",
       "4742  MH33D6-R      2024-11-06  3.366811e+06  222.720000           15116.786   \n",
       "4743  MH33D6-R      2024-11-07  3.438766e+06  227.480000           15116.786   \n",
       "4744  MH33D6-R      2024-11-08  3.430906e+06  226.960000           15116.786   \n",
       "4745  MH33D6-R      2024-11-11  3.389637e+06  224.230000           15116.786   \n",
       "4746  MH33D6-R      2024-11-12  3.389637e+06  224.230000           15116.786   \n",
       "\n",
       "     market_cap_currency  year  month  \n",
       "0                    USD  2006      1  \n",
       "1                    USD  2006      1  \n",
       "2                    USD  2006      1  \n",
       "3                    USD  2006      1  \n",
       "4                    USD  2006      1  \n",
       "...                  ...   ...    ...  \n",
       "4742                 USD  2024     11  \n",
       "4743                 USD  2024     11  \n",
       "4744                 USD  2024     11  \n",
       "4745                 USD  2024     11  \n",
       "4746                 USD  2024     11  \n",
       "\n",
       "[4747 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utilities.build_market_cap(fsym_id='MH33D6-R', market_cap_type='daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fasdfdsf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_stock_prices_split/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthis_fsym\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m     df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mfasdfdsf\u001b[49m\n\u001b[1;32m     28\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m df1[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsymId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 1. get shares outstanding\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fasdfdsf' is not defined"
     ]
    }
   ],
   "source": [
    "# CALCULATE MARKET CAP\n",
    "# use month end price data and combine with shares outstanding data\n",
    "\n",
    "# market cap parameters\n",
    "market_cap_type = 'daily'\n",
    "ffill_limit_dict = {'monthly': 16, 'daily': 375}\n",
    "assert market_cap_type in ['monthly', 'daily'], 'error: market_cap_type must be either monthly or daily'\n",
    "this_fsym = 'MH33D6-R'\n",
    "this_fsym='HTM0LK-R'\n",
    "\n",
    "\n",
    "# build the set of fsym_ids with semi annual share data\n",
    "semi_annual_share_dir = '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_shares_outstanding_semi_annual/'\n",
    "semi_annual_share_list = os.listdir(semi_annual_share_dir)\n",
    "semi_annual_share_list = [f for f in semi_annual_share_list if f.endswith('.csv')]\n",
    "semi_annual_share_list = [f.replace('.csv', '') for f in semi_annual_share_list ]\n",
    "\n",
    "\n",
    "# 0. get price data\n",
    "if market_cap_type == 'monthly':\n",
    "    df1 = pd.read_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_stock_prices_split_month_end/{this_fsym}.csv')\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df1 = df1[['fsymId', 'date', 'price', 'currency']]\n",
    "else:\n",
    "    df1 = pd.read_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_stock_prices_split/{this_fsym}.csv')\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df1 = df1[['fsymId', 'date', 'price', 'currency']]\n",
    "\n",
    "# 1. get shares outstanding\n",
    "df2 = pd.read_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_shares_outstanding_quarterly/{this_fsym}.csv')\n",
    "df2['fiscalEndDate'] = pd.to_datetime(df2['fiscalEndDate'])\n",
    "df2['epsReportDate'] = pd.to_datetime(df2['epsReportDate'])\n",
    "df2['epsReportDate'] = df2['epsReportDate'].fillna(df2['fiscalEndDate'] + pd.Timedelta(days=90))\n",
    "df2 = df2[['fsymId', 'epsReportDate', 'value']]\n",
    "df2.columns=['fsymId', 'date', 'shares_outstanding_quarterly']\n",
    "\n",
    "df3 = pd.read_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_shares_outstanding_annual/{this_fsym}.csv')\n",
    "df3['fiscalEndDate'] = pd.to_datetime(df3['fiscalEndDate'])\n",
    "df3['epsReportDate'] = pd.to_datetime(df3['epsReportDate'])\n",
    "df3['epsReportDate'] = df3['epsReportDate'].fillna(df3['fiscalEndDate'] + pd.Timedelta(days=90))\n",
    "df3 = df3[['fsymId', 'epsReportDate', 'value']]\n",
    "df3.columns=['fsymId', 'date', 'shares_outstanding_annual']\n",
    "\n",
    "# combine all shares outstanding data\n",
    "df4 = df2.merge(df3, how='outer', on=['fsymId', 'date'])\n",
    "\n",
    "# check if semi annual data exists\n",
    "if this_fsym in semi_annual_share_list:\n",
    "    df5 = pd.read_csv(f'/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_shares_outstanding_semi_annual/{this_fsym}.csv')\n",
    "    df5['fiscalEndDate'] = pd.to_datetime(df5['fiscalEndDate'])\n",
    "    df5['epsReportDate'] = pd.to_datetime(df5['epsReportDate'])\n",
    "    df5['epsReportDate'] = df5['epsReportDate'].fillna(df5['fiscalEndDate'] + pd.Timedelta(days=90))\n",
    "    df5 = df5[['fsymId', 'epsReportDate', 'value']]\n",
    "    df5.columns=['fsymId', 'date', 'shares_outstanding_semi_annual']\n",
    "\n",
    "    df4 = df4.merge(df5, how='outer', on=['fsymId', 'date'])\n",
    "\n",
    "# 2. merge shares outstanding with monthly prices\n",
    "df = df1.merge(df4, how='outer', on=['fsymId', 'date'])\n",
    "\n",
    "# 3. data cleaning\n",
    "# get the date of the first observation with non null price\n",
    "first_date = df[df['price'].notnull()]['date'].min()\n",
    "df = df[df['date'] >= first_date]\n",
    "\n",
    "# fill forward shares outstanding\n",
    "df = df.sort_values(by=['date'])\n",
    "df['shares_outstanding'] = df['shares_outstanding_quarterly'].fillna(df['shares_outstanding_annual'])\n",
    "df['shares_outstanding'] = df['shares_outstanding'].fillna(method='ffill', limit=ffill_limit_dict[market_cap_type])   # allow 12 months of fill forward (12 row) plut 4 more rows for quarterly financial filings\n",
    "\n",
    "# 4. market cap calculation (millions)\n",
    "df['market_cap'] = df['price'] * df['shares_outstanding']\n",
    "\n",
    "# 5. cleanup\n",
    "df = df[df['price'].notnull()]\n",
    "df = df[['fsymId', 'date', 'market_cap', 'price', 'shares_outstanding']]\n",
    "df.columns = ['fsym_id', 'market_cap_date', 'market_cap', 'price', 'shares_outstanding']\n",
    "df = df.sort_values(by=['fsym_id', 'market_cap_date'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['year'] = df['market_cap_date'].dt.year\n",
    "df['month'] = df['market_cap_date'].dt.month\n",
    "\n",
    "df.set_index('market_cap_date')['market_cap'].plot()\n",
    "\n",
    "\n",
    "\n",
    "df.tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>tradeCount</th>\n",
       "      <th>requestId</th>\n",
       "      <th>price</th>\n",
       "      <th>fsymId</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>611102576.0</td>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>11.141774</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>432208065.0</td>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>11.291920</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>709693860.0</td>\n",
       "      <td>2006-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>11.652769</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>511338507.0</td>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>11.683801</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363836568.0</td>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>51744.0</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>11.755368</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>33695538.0</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>488425.0</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>176.510000</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>25352939.0</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>395835.0</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>180.750000</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>22006182.0</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>322854.0</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>178.350000</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>17450354.0</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>254291.0</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>180.350000</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>25134905.0</td>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>301853.0</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>181.620000</td>\n",
       "      <td>HTM0LK-R</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4920 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           volume       date  tradeCount requestId       price    fsymId  \\\n",
       "0     611102576.0 2006-01-04         NaN  HTM0LK-R   11.141774  HTM0LK-R   \n",
       "1     432208065.0 2006-01-05         NaN  HTM0LK-R   11.291920  HTM0LK-R   \n",
       "2     709693860.0 2006-01-06         NaN  HTM0LK-R   11.652769  HTM0LK-R   \n",
       "3     511338507.0 2006-01-09         NaN  HTM0LK-R   11.683801  HTM0LK-R   \n",
       "4     363836568.0 2006-01-10     51744.0  HTM0LK-R   11.755368  HTM0LK-R   \n",
       "...           ...        ...         ...       ...         ...       ...   \n",
       "4915   33695538.0 2024-11-06    488425.0  HTM0LK-R  176.510000  HTM0LK-R   \n",
       "4916   25352939.0 2024-11-07    395835.0  HTM0LK-R  180.750000  HTM0LK-R   \n",
       "4917   22006182.0 2024-11-08    322854.0  HTM0LK-R  178.350000  HTM0LK-R   \n",
       "4918   17450354.0 2024-11-11    254291.0  HTM0LK-R  180.350000  HTM0LK-R   \n",
       "4919   25134905.0 2024-11-12    301853.0  HTM0LK-R  181.620000  HTM0LK-R   \n",
       "\n",
       "     currency  \n",
       "0         USD  \n",
       "1         USD  \n",
       "2         USD  \n",
       "3         USD  \n",
       "4         USD  \n",
       "...       ...  \n",
       "4915      USD  \n",
       "4916      USD  \n",
       "4917      USD  \n",
       "4918      USD  \n",
       "4919      USD  \n",
       "\n",
       "[4920 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Files from Local Directory to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factset_api_fundamentals_semi_annual\n",
      "file count: 21165\n",
      "start at: 19:33:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [43:51<00:00,  8.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count: 0\n",
      "\n",
      "factset_api_stock_prices_split\n",
      "file count: 21165\n",
      "start at: 20:17:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [41:49<00:00,  8.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count: 0\n",
      "\n",
      "factset_api_stock_returns\n",
      "file count: 21165\n",
      "start at: 20:59:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [43:26<00:00,  8.12it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count: 0\n",
      "\n",
      "factset_api_fundamentals_shares_outstanding_quarterly\n",
      "file count: 21165\n",
      "start at: 21:43:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [42:36<00:00,  8.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count: 0\n",
      "\n",
      "factset_api_fundamentals_shares_outstanding_annual\n",
      "file count: 21165\n",
      "start at: 22:25:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [42:23<00:00,  8.32it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count: 0\n",
      "\n",
      "factset_api_fundamentals_shares_outstanding_semi_annual\n",
      "file count: 21165\n",
      "start at: 23:08:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [41:46<00:00,  8.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count: 0\n",
      "\n",
      "factset_api_fundamentals_annual_assets_in_usd\n",
      "file count: 21165\n",
      "start at: 23:49:51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [47:51<00:00,  7.37it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count: 0\n",
      "\n",
      "factset_api_fundamentals_semi_annual_assets_in_usd\n",
      "file count: 21165\n",
      "start at: 00:37:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [42:09<00:00,  8.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "\n",
    "\n",
    "def s3_check_file_exists(bucket_name:str='qml-solutions-new-york', \n",
    "                         file_key:str='/factset-api-global-prices/B01DPB-R.csv', \n",
    "                         aws_access_key_id:str=None, \n",
    "                         aws_secret_access_key:str=None):\n",
    "    \n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket_name, Key=file_key)\n",
    "        return True\n",
    "    except s3.exceptions.ClientError:\n",
    "        return False\n",
    "\n",
    "def copy_file_to_s3(local_file_path:str=None, \n",
    "                     s3_bucket:str='qml-solutions-new-york', \n",
    "                     s3_key:str='factset-api-global-prices/', \n",
    "                     aws_access_key_id:str=None, \n",
    "                     aws_secret_access_key:str=None,\n",
    "                     verbose:bool=False):\n",
    "    \n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )   \n",
    "    try:\n",
    "        s3.upload_file(local_file_path, s3_bucket, s3_key)\n",
    "        if verbose:\n",
    "            print(f'--uploaded {local_file_path} to {s3_bucket}/{s3_key}')\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "# loop through files in local folder\n",
    "# Transfer file to AWS\n",
    "\n",
    "s3_bucket = 'qml-solutions-new-york'\n",
    "\n",
    "\n",
    "local_dir = '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data'\n",
    "error_dict = {}\n",
    "for source_folder in [\n",
    "    # 'factset_api_fundamentals_quarterly', \n",
    "    # 'factset_api_fundamentals_annual',\n",
    "\n",
    "    'factset_api_fundamentals_semi_annual',\n",
    "    'factset_api_stock_prices_split',\n",
    "    'factset_api_stock_returns',\n",
    "    'factset_api_fundamentals_shares_outstanding_quarterly',\n",
    "    'factset_api_fundamentals_shares_outstanding_annual',\n",
    "    'factset_api_fundamentals_shares_outstanding_semi_annual',\n",
    "    'factset_api_fundamentals_annual_assets_in_usd',\n",
    "    'factset_api_fundamentals_semi_annual_assets_in_usd',\n",
    "\n",
    "    ]:\n",
    "\n",
    "    print(source_folder)\n",
    "    target_folder = source_folder.replace('_', '-')\n",
    "    file_list = os.listdir(local_dir + '/' + source_folder + '/')\n",
    "    error_list = []\n",
    "    print('file count:', len(file_list))\n",
    "    print('start at:', datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    for file in tqdm.tqdm(file_list):\n",
    "\n",
    "        does_exist = s3_check_file_exists(bucket_name=s3_bucket, \n",
    "                            file_key=f'{target_folder}/{file}', \n",
    "                            aws_access_key_id=aws_credentials['key'], \n",
    "                            aws_secret_access_key=aws_credentials['secret'])\n",
    "\n",
    "        if not does_exist:\n",
    "\n",
    "            response = copy_file_to_s3(local_file_path=f'{local_dir}/{source_folder}/{file}', \n",
    "                                s3_bucket=s3_bucket, \n",
    "                            s3_key=f'{target_folder}/{file}', \n",
    "                            aws_access_key_id=aws_credentials['key'], \n",
    "                            aws_secret_access_key=aws_credentials['secret'],\n",
    "                            verbose=False)\n",
    "\n",
    "            if not response:\n",
    "                error_list.append(file)\n",
    "    \n",
    "    print('error count:', len(error_list))\n",
    "    print()\n",
    "    error_dict[source_folder] = error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transfer files from /Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_semi_annual\n",
      "transfer to s3 qml-solutions-new-york/factset-api-fundamentals-semi-annual\n",
      "files to transfer: 8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 8281/8281 [11:36<00:00, 11.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed uploads: 0\n",
      "Upload process complete.\n",
      "True []\n",
      "\n",
      "transfer files from /Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_annual_assets_in_usd\n",
      "transfer to s3 qml-solutions-new-york/factset-api-fundamentals-annual-assets-in-usd\n",
      "files to transfer: 98205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 98205/98205 [19:40<00:00, 83.19it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed uploads: 0\n",
      "Upload process complete.\n",
      "True []\n",
      "\n",
      "transfer files from /Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_semi_annual_assets_in_usd\n",
      "transfer to s3 qml-solutions-new-york/factset-api-fundamentals-semi-annual-assets-in-usd\n",
      "files to transfer: 98204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 98204/98204 [17:46<00:00, 92.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed uploads: 0\n",
      "Upload process complete.\n",
      "True []\n",
      "\n",
      "transfer files from /Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_shares_outstanding_annual\n",
      "transfer to s3 qml-solutions-new-york/factset-api-fundamentals-shares-outstanding-annual\n",
      "files to transfer: 21166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 21166/21166 [03:44<00:00, 94.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed uploads: 0\n",
      "Upload process complete.\n",
      "True []\n",
      "\n",
      "transfer files from /Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_shares_outstanding_quarterly\n",
      "transfer to s3 qml-solutions-new-york/factset-api-fundamentals-shares-outstanding-quarterly\n",
      "files to transfer: 21165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 21165/21165 [04:25<00:00, 79.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed uploads: 0\n",
      "Upload process complete.\n",
      "True []\n",
      "\n",
      "transfer files from /Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_fundamentals_shares_outstanding_semi_annual\n",
      "transfer to s3 qml-solutions-new-york/factset-api-fundamentals-shares-outstanding-semi-annual\n",
      "files to transfer: 8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 8281/8281 [01:29<00:00, 92.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed uploads: 0\n",
      "Upload process complete.\n",
      "True []\n",
      "\n",
      "transfer files from /Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_stock_prices_split\n",
      "transfer to s3 qml-solutions-new-york/factset-api-stock-prices-split\n",
      "files to transfer: 21165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 21165/21165 [34:42<00:00, 10.16it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed uploads: 0\n",
      "Upload process complete.\n",
      "True []\n",
      "\n",
      "transfer files from /Users/joeybortfeld/Documents/CreditGradients Data/Factset Data/factset_api_stock_returns\n",
      "transfer to s3 qml-solutions-new-york/factset-api-stock-returns\n",
      "files to transfer: 21165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 21165/21165 [27:18<00:00, 12.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed uploads: 0\n",
      "Upload process complete.\n",
      "True []\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MULTITHREAD BULK UPLOAD FROM LOCAL TO S3\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "\n",
    "\n",
    "def upload_file_to_s3(local_file_path, bucket_name, s3_key, s3_client):\n",
    "    \"\"\"\n",
    "    Uploads a single file to S3.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s3_client.upload_file(local_file_path, bucket_name, s3_key)\n",
    "        return True\n",
    "    except (BotoCoreError, ClientError) as e:\n",
    "        print(f\"Error uploading {local_file_path} to {bucket_name}/{s3_key}: {e}\")\n",
    "        return False\n",
    "\n",
    "def bulk_upload_to_s3(local_dir, local_folder, bucket_name, aws_access_key_id, aws_secret_access_key, num_threads=8):\n",
    "    \"\"\"\n",
    "    Uploads all files in local_dir to the specified S3 bucket.\n",
    "    \"\"\"\n",
    "    # Initialize S3 client \n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key\n",
    "    )\n",
    "\n",
    "    # Collect a list of local file names to transfer (aka 'MH33D6-R.csv', ''XQCWLZ-R.csv)\n",
    "\n",
    "    target_folder = local_folder.replace('_', '-')\n",
    "    local_file_list = os.listdir(local_dir + '/' + local_folder + '/')\n",
    "\n",
    "    local_path_list = [f'{local_dir}/{local_folder}/{f}' for f in local_file_list]\n",
    "    s3_key_list = [f'{target_folder}/{f}' for f in local_file_list]\n",
    "\n",
    "    from_to_list = list(zip(local_path_list, s3_key_list))\n",
    "\n",
    "    # diagnostics\n",
    "    print(f'transfer files from {local_dir}/{local_folder}')\n",
    "    print(f'transfer to s3 {bucket_name}/{target_folder}')\n",
    "    print('files to transfer:', len(from_to_list))\n",
    "\n",
    " \n",
    "    # Use ThreadPoolExecutor for parallel uploads\n",
    "    error_list = []\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = []\n",
    "        for local_path, s3_key in from_to_list:\n",
    "            futures.append(\n",
    "                executor.submit(upload_file_to_s3, local_path, bucket_name, s3_key, s3_client)\n",
    "            )\n",
    "\n",
    "        # Track progress with tqdm\n",
    "        for future in tqdm.tqdm(futures, desc=\"Uploading files\"):\n",
    "            try:\n",
    "                if not future.result():\n",
    "                    # Add failed uploads to the list\n",
    "                    error_list.append(futures[future])\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                error_list.append(futures[future])\n",
    "\n",
    "    \n",
    "    # collect and retry errors\n",
    "    print(f\"Failed uploads: {len(error_list)}\")\n",
    "    final_error_list = []\n",
    "    if error_list:\n",
    "        print(\"Retrying failed uploads...\")\n",
    "        for local_path, s3_key in error_list:\n",
    "            success = upload_file_to_s3(local_path, bucket_name, s3_key, s3_client)\n",
    "            if not success:\n",
    "                print(f\"Final failure for {local_path}\")\n",
    "                final_error_list.append(local_path)\n",
    "\n",
    "    print(\"Upload process complete.\")\n",
    "    if len(final_error_list) == 0:\n",
    "        return True, []\n",
    "    else:\n",
    "        return False, final_error_list\n",
    "\n",
    "# Example usage\n",
    "\n",
    "    \n",
    "local_dir = '/Users/joeybortfeld/Documents/CreditGradients Data/Factset Data'\n",
    "bucket_name = 'qml-solutions-new-york'\n",
    "\n",
    "for local_folder in [\n",
    "\n",
    "    # 'factset_api_fundamentals_annual',\n",
    "    # 'factset_api_fundamentals_quarterly',\n",
    "    'factset_api_fundamentals_semi_annual',\n",
    "\n",
    "    'factset_api_fundamentals_annual_assets_in_usd',\n",
    "    'factset_api_fundamentals_semi_annual_assets_in_usd',\n",
    "\n",
    "    'factset_api_fundamentals_shares_outstanding_annual',\n",
    "    'factset_api_fundamentals_shares_outstanding_quarterly',\n",
    "    'factset_api_fundamentals_shares_outstanding_semi_annual',\n",
    "\n",
    "    'factset_api_stock_prices_split',\n",
    "    'factset_api_stock_returns',\n",
    "    ]:\n",
    "\n",
    "    success, error_list = bulk_upload_to_s3(\n",
    "        local_dir=local_dir,\n",
    "        local_folder=local_folder,\n",
    "        bucket_name=bucket_name,\n",
    "        aws_access_key_id=aws_credentials['key'],\n",
    "        aws_secret_access_key=aws_credentials['secret'],\n",
    "        num_threads=8  # Adjust number of threads based on your system's capabilities\n",
    "    )\n",
    "\n",
    "    print(success, error_list)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W23Y3S-R.csv'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def s3_check_file_exists(bucket_name:str='qml-solutions-new-york', \n",
    "                         file_key:str='/factset-api-global-prices/B01DPB-R.csv', \n",
    "                         aws_access_key_id:str=None, \n",
    "                         aws_secret_access_key:str=None):\n",
    "    \n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket_name, Key=file_key)\n",
    "        return True\n",
    "    except s3.exceptions.ClientError:\n",
    "        return False\n",
    "\n",
    "\n",
    "s3_check_file_exists(bucket_name='qml-solutions-new-york', \n",
    "                         file_key='factset-api-stock-prices-split/MH33D6-R.csv', \n",
    "                         aws_access_key_id=aws_credentials['key'], \n",
    "                         aws_secret_access_key=aws_credentials['secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = pd.read_csv('s3://qml-solutions-new-york/factset-api-global-prices/B01DPB-R.csv',\n",
    "                   storage_options=aws_credentials)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Transfer file to AWS\n",
    "local_folder = '/Users/joeybortfeld/Documents/CreditGradients Data/factset_api_stock_prices/'\n",
    "s3_bucket = 'qml-solutions-new-york'\n",
    "\n",
    "\n",
    "\n",
    "def s3_check_file_exists(bucket_name:str='qml-solutions-new-york', \n",
    "                         file_key:str='/factset-api-global-prices/B01DPB-R.csv', \n",
    "                         aws_access_key_id:str=None, \n",
    "                         aws_secret_access_key:str=None):\n",
    "    \n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket_name, Key=file_key)\n",
    "        return True\n",
    "    except s3.exceptions.ClientError:\n",
    "        return False\n",
    "    \n",
    "# CHECK IF FILE EXISTS IN S3\n",
    "res = s3_check_file_exists(bucket_name=s3_bucket, \n",
    "                     file_key='factset-api-global-prices/B01DPB-R.csv', \n",
    "                     aws_access_key_id=aws_credentials['key'], \n",
    "                     aws_secret_access_key=aws_credentials['secret'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21165\n",
      "['factset-api-fundamentals-annual/B00M5L-R.csv', 'factset-api-fundamentals-annual/B018KB-R.csv', 'factset-api-fundamentals-annual/B01DPB-R.csv', 'factset-api-fundamentals-annual/B01HWF-R.csv', 'factset-api-fundamentals-annual/B01Q8M-R.csv', 'factset-api-fundamentals-annual/B02662-R.csv', 'factset-api-fundamentals-annual/B029D5-R.csv', 'factset-api-fundamentals-annual/B02Q5K-R.csv', 'factset-api-fundamentals-annual/B02ZTY-R.csv', 'factset-api-fundamentals-annual/B031TW-R.csv', 'factset-api-fundamentals-annual/B03872-R.csv', 'factset-api-fundamentals-annual/B03GM8-R.csv', 'factset-api-fundamentals-annual/B03WDN-R.csv', 'factset-api-fundamentals-annual/B045ZY-R.csv', 'factset-api-fundamentals-annual/B04FL9-R.csv']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "def list_s3_bucket_contents(bucket_name, prefix='', aws_access_key_id=None, aws_secret_access_key=None):\n",
    "    \"\"\"\n",
    "    List all items in an S3 bucket and subfolder.\n",
    "    \n",
    "    Parameters:\n",
    "    - bucket_name: str, name of the S3 bucket\n",
    "    - prefix: str, the folder path within the bucket (optional)\n",
    "    \n",
    "    Returns:\n",
    "    - List of file keys (paths) in the specified bucket and folder\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3', \n",
    "                             aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,)\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    \n",
    "    file_keys = []\n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                file_keys.append(obj['Key'])\n",
    "    \n",
    "    return file_keys\n",
    "\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "bucket_name = 'qml-solutions-new-york'\n",
    "folder_path = 'factset-api-fundamentals-annual/'  # Optional\n",
    "file_list = list_s3_bucket_contents(bucket_name, folder_path, aws_access_key_id=aws_credentials2['key'], aws_secret_access_key=aws_credentials2['secret'])\n",
    "print(len(file_list))\n",
    "print(file_list[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mutilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_fundamentals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMH33D6-R\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfield_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFF_BUS_DESC_ABBREV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# periodicity=download_type_dict[download_type][0],\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# start_date=start_date,\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# end_date=end_date,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# currency='USD',\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# verbose=False,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# authorization=authorization\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CreditGradients/code/Factset Tutorials/utilities.py:68\u001b[0m, in \u001b[0;36mdownload_fundamentals\u001b[0;34m(id_list, field_list, periodicity, start_date, end_date, currency, update_type, verbose, authorization)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Status: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fundamentals_response\u001b[38;5;241m.\u001b[39mstatus_code))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# create a dataframe from POST request, show dataframe properties\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m fundamentals_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfundamentals_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fundamentals_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [fundamentals_response\u001b[38;5;241m.\u001b[39mstatus_code, pd\u001b[38;5;241m.\u001b[39mDataFrame(fundamentals_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/investment_analysis/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/investment_analysis/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/investment_analysis/lib/python3.12/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "utilities.download_fundamentals(id_list=['MH33D6-R'],\n",
    "                                    field_list=['FF_BUS_DESC_ABBREV'],\n",
    "                                    # periodicity=download_type_dict[download_type][0],\n",
    "                                    # start_date=start_date,\n",
    "                                    # end_date=end_date,\n",
    "                                    # currency='USD',\n",
    "                                    # verbose=False,\n",
    "                                    # authorization=authorization\n",
    "                                    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "investment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
