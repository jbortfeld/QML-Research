{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sklearn.metrics\n",
    "\n",
    "from Py_Files import analytics\n",
    "from Py_Files import metric_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open modeling df\n",
    "df = pd.read_csv('/Users/annelilefranc/Documents/QML Files/modeling_dataset_with_bankruptcy_labels.csv')\n",
    "df['fiscal_end_date'] = df['fiscal_end_date'].apply(lambda x:pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_df_prep(df, test_split_date):\n",
    "    # in/out of sample split\n",
    "    if test_split_date is not None:\n",
    "        pct_df= df[df['fiscal_end_date'] < pd.to_datetime(test_split_date)].copy()\n",
    "    else:\n",
    "        pct_df = df.copy()\n",
    "\n",
    "    mask = pct_df[list(metric_inventory.display_name_dict)].isna().any(axis=1)\n",
    "    pct_df = pct_df[~mask]\n",
    "    pct_vars = []\n",
    "\n",
    "    # Apply percentile bins after splitting test/train dfs\n",
    "    for x in list(metric_inventory.display_name_dict):\n",
    "        this_boundaries = analytics.calculate_percentile_bins(pct_df, column=x, num_bins=100)\n",
    "        cutpoints_dict = {}\n",
    "        cutpoints_dict[x] = this_boundaries\n",
    "        try:\n",
    "            df[f'{x}_pct'] = analytics.assign_to_bins(df, column=x, boundaries=this_boundaries)\n",
    "            pct_vars.append(x)\n",
    "        except:\n",
    "            pass\n",
    "    pct_vars_dict = {f'{i}_pct':{'category': metric_inventory.display_name_dict[i]['category']} for i in pct_vars}\n",
    "\n",
    "    return df, pct_vars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_reg(df, vars, horizon, pct, test_split_date):\n",
    "\n",
    "    results_list = []\n",
    "    for var in vars:\n",
    "        category = vars[var]['category']\n",
    "\n",
    "        temp_df = df[df[var].notnull()].copy()\n",
    "        temp_df = temp_df[temp_df[var] != np.inf]\n",
    "        temp_df = temp_df[temp_df[var] != -np.inf]\n",
    "        temp_df['constant'] = 1\n",
    "\n",
    "        # if no percentile adjustment, winsorize\n",
    "        if pct == 'No':\n",
    "            lower, upper = temp_df[var].quantile([0.01, 0.99])\n",
    "            temp_df[var] = temp_df[var].clip(lower=lower, upper=upper)\n",
    "\n",
    "\n",
    "        # Create train/test dfs\n",
    "        if test_split_date is not None:\n",
    "            df_test = temp_df[temp_df['fiscal_end_date'] > pd.to_datetime(test_split_date)].copy()\n",
    "            df_train = temp_df[temp_df['fiscal_end_date'] <= pd.to_datetime(test_split_date)].copy()\n",
    "        else:\n",
    "            df_test = temp_df.copy()\n",
    "            df_train = temp_df.copy()\n",
    "        # Drop observations too close to default event\n",
    "        df_train = df_train[df_train[f'default_{horizon}'] != -1].copy()\n",
    "        # logit regression\n",
    "        y = df_train[f'default_{horizon}']\n",
    "        X = df_train[[var, 'constant']]\n",
    "\n",
    "\n",
    "        model = sm.Logit(y, X)\n",
    "        result = model.fit()\n",
    "\n",
    "        # Calculate in-sample AUROC\n",
    "        predictions = result.predict(X)\n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(y, predictions)\n",
    "        roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "        p_value = result.pvalues[var]\n",
    "        coeff = result.params[var]\n",
    "\n",
    "        # Calculate out_of-sample AUROC\n",
    "        predictions_o = result.predict(df_test[[var, 'constant']])\n",
    "        fpr_o, tpr_o, thresholds_o = sklearn.metrics.roc_curve(df_test[f'default_{horizon}'], predictions_o)\n",
    "        roc_auc_o = sklearn.metrics.auc(fpr_o, tpr_o)\n",
    "\n",
    "        results_list.append({\n",
    "            'Variable': var,\n",
    "            'Category': category,\n",
    "            'Coefficient': coeff,\n",
    "            'P-value': p_value,\n",
    "            'AUROC - Train': roc_auc,\n",
    "            'AUROC - Test': roc_auc_o\n",
    "        })\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model, pct_vars_dict = model_df_prep(df, None)\n",
    "df_model_split, pct_vars_dict_split = model_df_prep(df, '2018-01-01')\n",
    "\n",
    "for n in range(1,6):\n",
    "    horizon = n\n",
    "    print(f'Horizon: {n}')\n",
    "    # with pct transformation = No\n",
    "    #results = univariate_reg(df_model, display_name_dict, horizon, 'No', None)\n",
    "    #results.to_csv(f'/Users/annelilefranc/Documents/QML Files/univariate_reg_{n}y.csv', index=False)\n",
    "    # with train/test split\n",
    "    results = univariate_reg(df_model_split, metric_inventory.display_name_dict, horizon, 'No', '2018-01-01')\n",
    "    results.to_csv(f'/Users/annelilefranc/Documents/QML Files/univariate_reg_{n}y_split.csv', index=False)\n",
    "\n",
    "    # with pct transformation = Yes\n",
    "    #results = univariate_reg(df_model, pct_vars_dict, horizon, 'Yes', None)\n",
    "    #results.to_csv(f'/Users/annelilefranc/Documents/QML Files/univariate_reg_{n}y-pct.csv', index=False)\n",
    "    # with train/test split\n",
    "    results = univariate_reg(df_model_split, pct_vars_dict_split, horizon, 'Yes', '2018-01-01')\n",
    "    results.to_csv(f'/Users/annelilefranc/Documents/QML Files/univariate_reg_{n}y-pct_split.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
