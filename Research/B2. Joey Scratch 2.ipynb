{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "import tqdm\n",
    "import os\n",
    "from Py_Files import credentials\n",
    "from Py_Files import factset_api\n",
    "from Py_Files import financial_modeling_prep as fmp\n",
    "from Py_Files import qml_equity_ratios\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/joeybortfeld/Documents/QML Solutions Data/'\n",
    "\n",
    "date_range = pd.date_range(start='2021-01-21', end='2021-10-31', freq='ME')\n",
    "date_range = [d.strftime('%m%d%Y') for d in date_range]\n",
    "\n",
    "collection = []\n",
    "for date in tqdm.tqdm(date_range):\n",
    "    temp = pd.read_excel(data_dir + f'ice_data/history/old_constituents/C0A0-{date}.xlsx', skiprows=1)\n",
    "    temp = temp[temp['ISIN number'].notnull()]\n",
    "    temp.columns = [c.lower().replace(' ', '_') for c in temp.columns]\n",
    "    temp['date'] = pd.to_datetime(date, format='%m%d%Y')\n",
    "\n",
    "    collection.append(temp)\n",
    "\n",
    "df = pd.concat(collection, axis=0)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rating_to_num_dict = {'AAA': 21, 'AA1': 20, 'AA2': 19, 'AA3': 18, \n",
    "                      'A1': 17, 'A2': 16, 'A3': 15, \n",
    "                      'BBB1': 14, 'BBB2': 13, 'BBB3': 12, \n",
    "                      'BB1': 11, 'BB2': 10, 'BB3': 9,\n",
    "                      'B1': 8, 'B2': 7, 'B3': 6, \n",
    "                      'CCC1': 5, 'CCC2': 4, 'CCC3': 3, \n",
    "                      'CC': 2, 'C': 1, 'D': 0}\n",
    "\n",
    "df['rating_num'] = df['rating'].map(rating_to_num_dict)\n",
    "df['oas_prevmend'] = df['oas'] - df['oas_mtd_change']\n",
    "df = df.columne(rename=['%_mktval-prevmend': '%_mkt_value_prevmend'])\n",
    "# calculate returns by description and ticker\n",
    "\n",
    "suffix_dict = {'cusip':'_by_bond', 'ticker':'_by_ticker', 'description':'_by_description'}\n",
    "\n",
    "# calculate aggregations by ticker and description\n",
    "for group in ['cusip', 'ticker', 'description']:\n",
    "\n",
    "    this_suffix = suffix_dict[group]\n",
    "    df[f'total_weight{this_suffix}'] = df.groupby(by=[group, 'date'])['%_mkt_value'].transform('sum')\n",
    "    df[f'weight{this_suffix}'] = df['%_mkt_value'] / df[f'total_weight{this_suffix}']\n",
    "\n",
    "    # calculate market-weighted ametrics by group\n",
    "    # - excess return\n",
    "    # - oas\n",
    "    for m in ['excess_return_%_mtd', 'oas',]:\n",
    "        df[f'{m}{this_suffix}'] = df[m] * df[f'weight{this_suffix}']\n",
    "        df[f'{m}{this_suffix}'] = df.groupby(by=[group, 'date'])[f'{m}{this_suffix}'].transform('sum')\n",
    "\n",
    "    # calculate size by group\n",
    "    df[f'total_mkt_value{this_suffix}'] = df.groupby(by=[group, 'date'])['%_mkt_value'].transform('sum')\n",
    "    temp = df.drop_duplicates(subset=[group, 'date'])[['date', group, f'total_mkt_value{this_suffix}']]\n",
    "    temp[f'size{this_suffix}'] = temp.groupby(by=[group, 'date'])[f'total_mkt_value{this_suffix}'].transform('sum')\n",
    "\n",
    "# calculate factors (decile ranks)\n",
    "for group in ['cusip', 'ticker', 'description']:\n",
    "\n",
    "    for factor in [\n",
    "        ('size_factor', 'total_mkt_value'), \n",
    "        ('carry_factor', 'oas'),\n",
    "        ]:\n",
    "\n",
    "        factor_name = factor[0]\n",
    "        factor_col = factor[1]\n",
    "\n",
    "        this_suffix = suffix_dict[group]\n",
    "        temp = df.drop_duplicates(subset=['date', group], keep='first')\n",
    "        temp[f'{factor_name}{this_suffix}'] = temp.groupby(by=['date'])[f'{factor_col}{this_suffix}'].transform(lambda x: pd.qcut(x, q=10, labels=False, duplicates='drop'))\n",
    "        temp = temp[[group, 'date', f'{factor_name}{this_suffix}']]\n",
    "        df = df.merge(temp, on=[group, 'date'], how='left')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_fsym = 'MH33D6-R'\n",
    "\n",
    "temp1 = pd.read_csv(f'/Users/joeybortfeld/Documents/QML Solutions Data/factset_data/factset_fundamentals/quarterly/{this_fsym}.csv')\n",
    "temp1 = temp1[temp1['metric'] == 'FF_COM_SHS_OUT']\n",
    "temp1 = temp1[['fsymId', 'fiscalEndDate', 'epsReportDate', 'value']]\n",
    "temp1.columns = ['fsym_id', 'fiscal_end_date', 'report_date', 'ff_com_shs_out']\n",
    "temp1['report_month'] = pd.to_datetime(temp1['report_date']).dt.month\n",
    "temp1['report_year'] = pd.to_datetime(temp1['report_date']).dt.year\n",
    "\n",
    "temp2 = pd.read_csv(f'/Users/joeybortfeld/Documents/QML Solutions Data/factset_data/factset_equity/shares/{this_fsym}.csv')\n",
    "temp2['report_year'] = pd.to_datetime(temp2['date']).dt.year\n",
    "temp2['report_month'] = pd.to_datetime(temp2['date']).dt.month\n",
    "temp2 = temp2[['report_year', 'report_month', 'totalOutstanding']]\n",
    "\n",
    "temp = temp1.merge(temp2, on=['report_year', 'report_month'], how='left')\n",
    "temp.set_index('fiscal_end_date')[['ff_com_shs_out', 'totalOutstanding']].plot(figsize=(10, 5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.groupby(by='size_factor_by_ticker')['excess_return_%_mtd_by_ticker'].median().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bond-level analysis\n",
    "\n",
    "# description-level analysis\n",
    "\n",
    "# ticker    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_groupby_return(data, groupby_col, return_col, calc_method='mean'):\n",
    "\n",
    "    df = data.groupby(groupby_col, as_index=False)[return_col].apply(calc_method)\n",
    "    df.columns = ['cohort', 'value']\n",
    "    df['grouping'] = groupby_col\n",
    "    df['calc_method'] = calc_method\n",
    "    df['metric'] = return_col\n",
    "    df = df[['grouping','metric', 'calc_method', 'cohort', 'value']]\n",
    "\n",
    "    return df\n",
    "calc_groupby_return(df, 'rating_num', 'excess_return_%_mtd')\n",
    "# calc_groupby_return(df, 'rating_num', 'total_return_%_mtd_loc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_factor(df):\n",
    "\n",
    "    df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bond count', len(temp))\n",
    "print('description count', len(temp['description'].unique()))\n",
    "print('ticker count', len(temp['ticker'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_fsyms[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'liquidity'\n",
    "# metric = 'P-value'\n",
    "# metric = 'Coefficient'\n",
    "metric ='AUROC - Train'\n",
    "\n",
    "collection = []\n",
    "for i in [1,2,3,4,5]:\n",
    "    temp = pd.read_csv(f'/Users/joeybortfeld/Downloads/univariate_reg_{i}y-pct_split.csv')\n",
    "    temp['t'] = i\n",
    "    collection.append(temp)\n",
    "\n",
    "df = pd.concat(collection, axis=0)\n",
    "\n",
    "print(df['Category'].unique())\n",
    "\n",
    "df['P-value'] = df['P-value'].map(lambda x: f\"{x:.3f}\")\n",
    "df['AUROC - Train'] = df['AUROC - Train'].map(lambda x: f\"{x:.2f}\")\n",
    "df['Coefficient'] = df['Coefficient'].map(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "\n",
    "df = df[df['Category'] == category]\n",
    "\n",
    "df = df.pivot(index='Variable', columns='t', values=metric)\n",
    "df = df.sort_values(by=5, ascending=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "def merton_distance_to_default(market_cap, debt, equity_vol, risk_free_rate=0.03, time_horizon=1):\n",
    "    \"\"\" Computes Distance to Default (DD) using Merton's structural model. \"\"\"\n",
    "    \n",
    "    # Initial guess: Assume asset value is close to market cap\n",
    "    asset_value = market_cap\n",
    "    asset_vol = equity_vol  # Approximate initial asset volatility\n",
    "\n",
    "    def equations(vars):\n",
    "        A, sigma_A = vars\n",
    "        d1 = (np.log(A / debt) + (risk_free_rate + 0.5 * sigma_A ** 2) * time_horizon) / (sigma_A * np.sqrt(time_horizon))\n",
    "        d2 = d1 - sigma_A * np.sqrt(time_horizon)\n",
    "\n",
    "        eq1 = market_cap - (A * norm.cdf(d1) - np.exp(-risk_free_rate * time_horizon) * debt * norm.cdf(d2))\n",
    "        eq2 = equity_vol * market_cap - norm.cdf(d1) * A * sigma_A\n",
    "\n",
    "        return [eq1, eq2]\n",
    "\n",
    "    # Solve for asset value (A) and asset volatility (sigma_A)\n",
    "    A, sigma_A = fsolve(equations, [asset_value, asset_vol])\n",
    "\n",
    "    # Compute Distance to Default\n",
    "    d1 = (np.log(A / debt) + (risk_free_rate + 0.5 * sigma_A ** 2) * time_horizon) / (sigma_A * np.sqrt(time_horizon))\n",
    "    d2 = d1 - sigma_A * np.sqrt(time_horizon)\n",
    "    \n",
    "    distance_to_default = d2\n",
    "    probability_of_default = norm.cdf(-distance_to_default)\n",
    "\n",
    "    return distance_to_default, probability_of_default\n",
    "\n",
    "# Example Firm Data\n",
    "market_cap = 36_702_000_000  # $5 billion\n",
    "debt = 3_000_000_000        # $3 billion in debt\n",
    "equity_vol = 0.30           # 30% annualized volatility\n",
    "\n",
    "# Compute DD and PD\n",
    "dd, pd = merton_distance_to_default(market_cap, debt, equity_vol)\n",
    "print(f\"Distance to Default: {dd:.7f}\")\n",
    "print(f\"Probability of Default: {pd:.7%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp['date'] < pd.to_datetime('2000-01-01')].set_index('date')['price'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fsyms = os.listdir('/Users/joeybortfeld/Documents/QML Solutions Data/factset_data/factset_equity/prices SPLIT/')\n",
    "split_fsyms = [i.split('.')[0] for i in split_fsyms]\n",
    "\n",
    "unsplit_fsyms = os.listdir('/Users/joeybortfeld/Documents/QML Solutions Data/factset_data/factset_equity/prices UNSPLIT/')\n",
    "unsplit_fsyms = [i.split('.')[0] for i in unsplit_fsyms]\n",
    "\n",
    "excel_fsyms = os.listdir('/Users/joeybortfeld/Documents/QML Solutions Data/factset_data/factset_equity/excel_addin_download/')\n",
    "excel_fsyms = [i.split('_')[0] for i in excel_fsyms]\n",
    "\n",
    "share_fsyms = os.listdir('/Users/joeybortfeld/Documents/QML Solutions Data/factset_data/factset_equity/shares/')\n",
    "share_fsyms = [i.split('.')[0] for i in share_fsyms]\n",
    "\n",
    "print('split', len(split_fsyms))\n",
    "print('unsplit', len(unsplit_fsyms))\n",
    "print('excel', len(excel_fsyms))\n",
    "print('shares', len(share_fsyms))\n",
    "\n",
    "[f for f in excel_fsyms if not f in split_fsyms]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, temp1 = factset_api.get_stock_prices(id_list=[this_fsym], \n",
    "field_list=['price', 'volume', 'tradeCount'], \n",
    "start_date='2006-01-06', \n",
    "end_date='2024-12-31', \n",
    "frequency='D',\n",
    "split='SPLIT',\n",
    "verbose=True,\n",
    "authorization=credentials.factset_api_authorization)\n",
    "\n",
    "temp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_fsym = 'MH33D6-R'\n",
    "\n",
    "response, temp1 = factset_api.get_stock_prices(id_list=[this_fsym], \n",
    "field_list=['price', 'volume', 'tradeCount'], \n",
    "start_date='2006-01-06', \n",
    "end_date='2024-12-31', \n",
    "frequency='D',\n",
    "split='SPLIT',\n",
    "authorization=credentials.factset_api_authorization)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 5), ncols=2)\n",
    "temp.set_index('date')['price'].plot(ax=axes[0])\n",
    "\n",
    "response, temp2 = factset_api.get_shares_outanding(id_list=[this_fsym], \n",
    "                     start_date='2006-03-31', \n",
    "                     end_date='2024-12-31', \n",
    "                     frequency='M',\n",
    "                     verbose=False,\n",
    "                     authorization=credentials.factset_api_authorization)\n",
    "\n",
    "print(response)\n",
    "temp2.set_index('date')['totalOutstanding'].plot(ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp1.merge(temp2, on='date', how='outer')\n",
    "temp['totalOutstanding'] = temp['totalOutstanding'].fillna(method='ffill')\n",
    "fig, ax = plt.subplots(figsize=(10, 5), ncols=2)\n",
    "temp.set_index('date')[['totalOutstanding', 'price']].plot(secondary_y='totalOutstanding', ax=ax[0])\n",
    "\n",
    "temp['market_cap'] = temp['totalOutstanding'] * temp['price']\n",
    "temp['market_cap'].plot(ax=ax[1])\n",
    "ax[0].set_title('Total Outstanding and Price')\n",
    "ax[1].set_title('Market Cap')\n",
    "plt.show()\n",
    "\n",
    "temp['year'] = pd.to_datetime(temp['date']).dt.year\n",
    "temp = temp.drop_duplicates(subset=['year'], keep='last')\n",
    "temp['market_cap'] /= 1_000\n",
    "temp[['date', 'market_cap', 'price']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Download using SPLIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, temp = factset_api.download_fundamentals(id_list=['MH33D6-R'], \n",
    "                                #   field_list=['FF_IS_MULTI_SHARE', 'FF_IS_ADR'],\n",
    "                                  field_list=['FF_COM_SHS_OUT'],\n",
    "                                    periodicity='ANN', \n",
    "                                    start_date='1990-01-01', \n",
    "                                    end_date='2024-12-31', \n",
    "                                    currency='LOCAL',\n",
    "                                    update_type='RP', \n",
    "                                    verbose=True, \n",
    "                                    authorization=credentials.factset_api_authorization)\n",
    "temp.set_index('reportDate')['value'].plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://api.factset.com/content/factset-global-prices/v1/prices?ids=CGF31Z-R&fields=price,priceOpen,priceHigh,priceLow,volume&startDate=2024-01-01&endDate=2024-08-27&frequency=D&calendar=FIVEDAY&currency=EUR&adjust=SPLIT&batch=N'\n",
    "\n",
    "headers = {'Accept': 'application/json','Content-Type': 'application/json'}\n",
    "\n",
    "response = requests.get(url, headers=headers, auth = credentials.factset_api_authorization)\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cagr(initial, final, years):\n",
    "    return (final / initial) ** (1 / years) - 1\n",
    "\n",
    "# Parameters\n",
    "initial_revenue = 1.00\n",
    "initial_expenses = 0.30\n",
    "initial_net_income = initial_revenue - initial_expenses\n",
    "\n",
    "years = 5\n",
    "\n",
    "# Define revenue and expense growth rates to iterate over\n",
    "revenue_growth_rates = np.arange(0.01, 0.1, 0.01)  # 1% to 5%\n",
    "expense_growth_rates = np.arange(0.01, 0.1, 0.01)  # 1% to 5%\n",
    "\n",
    "# Create table\n",
    "cagr_table = pd.DataFrame(index=[f\"{e*100:.0f}%\" for e in expense_growth_rates],\n",
    "                          columns=[f\"{r*100:.0f}%\" for r in revenue_growth_rates])\n",
    "\n",
    "for e_growth in expense_growth_rates:\n",
    "    for r_growth in revenue_growth_rates:\n",
    "        # Compute revenue and expense projections\n",
    "        final_revenue = initial_revenue * (1 + r_growth) ** years\n",
    "        final_expenses = initial_expenses * (1 + e_growth) ** years\n",
    "        final_net_income = final_revenue - final_expenses\n",
    "        \n",
    "        # Compute CAGR of net income\n",
    "        cagr_net_income = calculate_cagr(initial_net_income, final_net_income, years)\n",
    "        cagr_table.loc[f\"{e_growth*100:.0f}%\", f\"{r_growth*100:.0f}%\"] = f\"{cagr_net_income*100:.2f}%\"\n",
    "\n",
    "# Display the result\n",
    "cagr_table.to_csv('/Users/joeybortfeld/Downloads/cagr_table.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "investment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
